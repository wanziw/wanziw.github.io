<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>python基础配置</title>
      <link href="/2024/11/04/python%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/"/>
      <url>/2024/11/04/python%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title></title>
      <link href="/2024/10/26/%E6%A4%8D%E7%89%A9%E5%8D%95%E7%BB%86%E8%83%9E%E5%A4%9A%E7%BB%84%E5%AD%A6%E6%96%87%E7%AB%A0/"/>
      <url>/2024/10/26/%E6%A4%8D%E7%89%A9%E5%8D%95%E7%BB%86%E8%83%9E%E5%A4%9A%E7%BB%84%E5%AD%A6%E6%96%87%E7%AB%A0/</url>
      
        <content type="html"><![CDATA[<h1>园艺 和 单细胞多组学</h1><h1>Application of single-cell multi-omics approaches in horticulture research</h1><h2 id="introduction">introduction</h2><ul><li>Cell heterogeneity  controls<ul><li>plant cell differentiation 细胞分化</li><li>metabolic partitioning 代谢分配</li><li>environmental response 环境相应</li></ul></li></ul><p>这些控制都是在single-cell resolution（分辨率）下characterize的</p><p>现在的tech可以让多组学对 isolated single plant cells进行analyze 来dissect intercellular regulatory mechanisms</p><p>这些单细胞多组学技术适合 <strong>clarify the development of horticultural plants</strong>和<strong>uncover intercellular regulatory mechanisms</strong></p><h2 id="单细胞多组学发展">单细胞多组学发展</h2><ul><li><p>Table1 总结了很多plant中的单细胞多组学研究文章</p><ul><li>先根据不同的omics分</li><li>然后根据使用的测序的protocol分</li><li>再列出其中研究过的物种、器官/组织<ul><li>Arabidopsis 拟南芥</li><li>Maize 玉米</li><li>Medicago 苜蓿</li><li>Soybean 大豆</li><li>Brassica rapa   芜菁（白菜的一种）</li><li>Litchi 荔枝</li></ul></li></ul></li><li><p>转录组学</p><ul><li>因为细胞壁的存在导致单个植物细胞难以分离，scRNA-seq不好用</li><li>所以是snRNA-seq（single-nucleus RNA sequencing）提供了办法，提取细胞核中的RNA</li></ul></li><li><p>表观遗传组学</p><ul><li>DNA methylation, chromatin accessibility, histone modifications, and 3D genome structure</li><li>介绍了一些不同的技术</li></ul></li><li><p>蛋白质组学</p><ul><li>对蛋白质组和翻译后修饰post-translational modifications (PTM) 进行解析</li></ul></li><li></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Overleaf学习</title>
      <link href="/2024/10/25/Overleaf%E5%AD%A6%E4%B9%A0/"/>
      <url>/2024/10/25/Overleaf%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h1>Overleaf学习</h1><p><a href="https://blog.csdn.net/m0_37201243/article/details/120170141">【论文写作】使用overleaf撰写你的会议论文</a></p><h1>要点</h1><ul><li>中间空一行就是分段</li></ul><h2 id="分节">分节</h2><ul><li>\section{introduction}</li><li>\subsection{}</li></ul><h2 id="公式">公式</h2><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line">a+b=<span class="keyword">\gamma</span><span class="keyword">\Label</span>&#123;eq&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br></pre></td></tr></table></figure><h2 id="表格">表格</h2><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure><p>表格中间的内容可以利用一些在线网站生成</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;table&#125;</span><br><span class="line">  <span class="keyword">\caption</span>&#123;Frequency of Special Characters&#125;</span><br><span class="line">  <span class="keyword">\label</span>&#123;tab:freq&#125;</span><br><span class="line">  <span class="keyword">\begin</span>&#123;tabular&#125;&#123;ccl&#125;</span><br><span class="line">    <span class="keyword">\toprule</span></span><br><span class="line">    Non-English or Math<span class="built_in">&amp;</span>Frequency<span class="built_in">&amp;</span>Comments<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\midrule</span></span><br><span class="line">    <span class="keyword">\O</span> <span class="built_in">&amp;</span> 1 in 1,000<span class="built_in">&amp;</span> For Swedish names<span class="keyword">\\</span></span><br><span class="line">    <span class="built_in">$</span><span class="keyword">\pi</span><span class="built_in">$</span> <span class="built_in">&amp;</span> 1 in 5<span class="built_in">&amp;</span> Common in math<span class="keyword">\\</span></span><br><span class="line">    <span class="keyword">\$</span> <span class="built_in">&amp;</span> 4 in 5 <span class="built_in">&amp;</span> Used in business<span class="keyword">\\</span></span><br><span class="line">    <span class="built_in">$</span><span class="keyword">\Psi</span><span class="built_in">^</span>2<span class="built_in">_</span>1<span class="built_in">$</span> <span class="built_in">&amp;</span> 1 in 40,000<span class="built_in">&amp;</span> Unexplained usage<span class="keyword">\\</span></span><br><span class="line">  <span class="keyword">\bottomrule</span></span><br><span class="line"><span class="keyword">\end</span>&#123;tabular&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;table&#125;</span><br></pre></td></tr></table></figure><h2 id="图片">图片</h2><p>一般项目会创建一个文件夹叫做figure用来存图片</p><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\begin</span>&#123;figure&#125;[h]</span><br><span class="line">  <span class="keyword">\centering</span></span><br><span class="line">  <span class="keyword">\includegraphics</span>[width=<span class="keyword">\linewidth</span>]&#123;sample-franklin&#125;</span><br><span class="line">  <span class="keyword">\caption</span>&#123;1907 Franklin Model D roadster. Photograph by Harris <span class="keyword">\&amp;</span></span><br><span class="line">    Ewing, Inc. [Public domain], via Wikimedia</span><br><span class="line">    Commons. (<span class="keyword">\url</span>&#123;<span class="link">https://goo.gl/VLCRBB</span>&#125;).&#125;</span><br><span class="line">  <span class="keyword">\Description</span>&#123;A woman and a girl in white dresses sit in an open car.&#125;</span><br><span class="line"><span class="keyword">\end</span>&#123;figure&#125;</span><br></pre></td></tr></table></figure><h1>参考文献</h1><p>zotero下载插件 better bibtex</p><p>zotero</p><ul><li>右键文件夹-&gt;导出 BibTex格式-&gt;生成bib文件并命名</li></ul><p>Overleaf</p><ul><li>上传bib文件到overleaf项目里</li><li>主文件最后输<ul><li>假设文件叫做myreference.bib</li><li><code>\bibliographystyle&#123;plain&#125;</code><ul><li>定义style，比如让参考文献按照首字母排序还是引用顺序排序</li><li>一般期刊会给个cls文件来定义这些</li></ul></li><li><code>\bibliography&#123;myreference&#125;</code></li></ul></li><li>文章中插入引用<ul><li>\cite{}</li><li>可以选择</li></ul></li><li>期刊对引用文献的要求<ul><li>在zetero首选项里打开better bibtex<ul><li>“导出”-&gt;“字段”</li><li>对不导出的部分，我们进行删除就行</li></ul></li></ul></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>单细胞多组学论文阅读笔记</title>
      <link href="/2024/10/25/%E5%8D%95%E7%BB%86%E8%83%9E%E5%A4%9A%E7%BB%84%E5%AD%A6%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"/>
      <url>/2024/10/25/%E5%8D%95%E7%BB%86%E8%83%9E%E5%A4%9A%E7%BB%84%E5%AD%A6%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1>目录</h1><p>[toc]</p><h1>本人研究方向</h1><p>目前学习路径</p><ol><li><p>植物的单细胞多组学：大部分是不基于深度学习的，先掌握了解，</p><ul><li>Application of single-cell multi-omics approaches in horticulture research</li></ul></li><li><p>基于深度学习的单细胞多组学，特别是代谢组学这块，主要是人类的研究，先模仿</p><ul><li>Machine Learning Using Neural Networks for Metabolomic Pathway Analyses<ul><li><a href="https://github.com/jp-um/machine_learning_for_metabolomic_pathway_analyses">https://github.com/jp-um/machine_learning_for_metabolomic_pathway_analyses</a></li></ul></li></ul></li></ol><h1>单细胞多组学</h1><table><thead><tr><th>模型类别</th><th>方法</th><th>年份</th><th>文献</th><th>数据集</th><th>技术特点</th><th>创新点</th><th>备注</th></tr></thead><tbody><tr><td><strong>VAE</strong></td><td><strong>SCIM</strong></td><td>2020</td><td>SCIM: universal single-cell matching with unpaired feature sets</td><td><strong>技术</strong>：CyTOF（测量蛋白质表达） scRNA-seq<br/><strong>数据集</strong>：Melanoma Tumor Sample（黑色素瘤）、Human Bone Marrow Sample（人类骨髓）<br/><strong>数据类型</strong>：unpaired</td><td>1. <strong>Multimodal autoencoders</strong> with an adversarial objective<br/>2. <strong>基于低维潜在表示的二分匹配方案</strong></td><td>解决了不同单细胞技术因细胞消耗而导致的配对对应关系丢失问题<br/>通过可扩展的算法在大规模单细胞数据中匹配不同技术下的细胞测量</td><td><strong>利用模拟数据</strong>，通过细胞分化的进展顺序来评估 pseudotime 来证明匹配效果。<br/>然后在使用真实数据集</td></tr><tr><td><strong>VAE</strong></td><td><strong>scMM</strong></td><td>2021</td><td>A mixture-of-experts deep generative model for integrated analysis of single-cell multiomics data</td><td><strong>技术</strong>：CITE-seq（同时测量 surface protein 和 RNA-seq）、SHARE-seq（同时测量 ATAC-seq、RNA-seq）<br/><strong>数据集</strong>：Human PBMC（外周血单核细胞）、BMNC（人类骨髓、单核细胞）、Mouse skin<br/><strong>数据类型</strong>：paired</td><td>1. <strong>Mixture-of-experts deep generative model</strong>（混合专家）<br/>2. <strong>Multimodal VAE</strong><br/>3. <strong>Pseudocell generation</strong>（伪细胞生成策略）</td><td><strong>能预测缺失的模态</strong></td><td></td></tr><tr><td><strong>VAE</strong></td><td><strong>Cobolt</strong></td><td>2021</td><td>Cobolt: integrative analysis of multimodal single-cell sequencing data</td><td><strong>技术</strong>：SHARE-seq、10X Multiome（PBMCs mRNA-seq + ATAC-seq）<br/><strong>数据集</strong>：Adult mouse cerebral cortices (成年小鼠大脑皮层)、Human PBMC<br/><strong>数据类型</strong>：paired</td><td>1. <strong>多编码器和多解码器</strong></td><td><strong>处理单模态和联合模态数据</strong><br/><strong>扩大了适用范围</strong></td><td>1. <strong>多模态数据之间</strong>：paired 数据之间整合，不同模态在同一共享的 latent space 表示细胞，提升细胞类型识别精度<br/>2. <strong>多模态和单模态数据之间整合</strong>：Human PBMC 中，将 10X Multiome 的 multi data 与单独的 scRNA-seq 和 scATAC-seq 数据结合</td></tr><tr><td><strong>VAE</strong></td><td><strong>scMAVE</strong></td><td>2021</td><td>Deep-joint-learning analysis model of single cell transcriptome and open chromatin accessibility data</td><td><strong>技术</strong>：SHARE-seq、scCAT-seq (ATAC + RNA)<br/><strong>数据集</strong>：Human cell lines mixture、AdBrainCortex (Adult mouse cerebral cortices)<br/><strong>数据类型</strong>：paired</td><td>1. <strong>MVAE + GMM</strong><br/>2. <strong>3 strategies</strong> (product of experts, neural network, direct concatenation)</td><td><strong>多种联合学习策略</strong>，针对数据的稀疏性和异质性问题改进了 joint embedding 的 quality</td><td>1. <strong>数据预处理</strong><br/>   - <strong>RNA</strong>：使用 scVI 或 Seurat 进行初步处理和降维<br/>   - <strong>ATAC</strong>：采用 <strong>ZINB（零膨胀负二项分布）</strong> 建模，处理数据的稀疏性和异质性</td></tr><tr><td><strong>VAE</strong></td><td><strong>scMVP</strong></td><td>2022</td><td>A deep generative model for multi-view profiling of single-cell RNA-seq and ATAC-seq data.</td><td><strong>技术</strong>：SHARE-seq、sci-CAR、Paired-seq、SHARE-seq、10X Genomics Multiome<br/><strong>数据集</strong>：Mouse cerebral cortex (GSE126074)、Human and mouse (GSM3271040, GSM3271040)、Mouse (GSE130399)、Mouse skin (GSE140203)、Human PBMC and lymph nod<br/><strong>数据类型</strong>：paired</td><td><strong>Multimodal VAE with Gaussian mixture prior and attention modules</strong></td><td><strong>引入了注意力机制</strong></td><td>1. <strong>生物学解释方面</strong>：转录调控，可以识别已知的转录因子-目标基因 pair。法语轨迹推断，推断细胞的发育轨迹<br/>2. <strong>注意力机制方面</strong>：RNA 子网络，mask attention，专注于 scRNA-seq 数据中的局部语义区域。ATAC 子网络的 multi-head self-attention，数据稀疏且高维，可以捕捉长距离的相关性<br/>3. <strong>模型</strong>：GMM 作为 prior distribution + VAE</td></tr></tbody></table><h3 id=""></h3><h1>一篇综述</h1><p><a href="https://academic.oup.com/bib/article/24/5/bbad313/7256792">https://academic.oup.com/bib/article/24/5/bbad313/7256792</a></p><h2 id="introduction">introduction</h2><blockquote><ol><li>第一段<ul><li>Recently，多模式深度学习（MDL）方法的发展激增</li></ul></li><li>第二段<ul><li>点评一下当前使用多模态进行单细胞数据integration的challenges<ul><li>overfitting</li><li>Sparsity of data</li></ul></li></ul></li><li>第三段<ul><li>点评一些该领域别人写的review<ul><li>目前有一些单细胞多组学整合算法的综述，However都 focused on MDL之外的方法</li><li>而且不包含最新的方法</li></ul></li><li>最后说对the published work进行了分类<ul><li>based on MDL model architecture, fusion strategy, key integration tasks and downstream biological analysis</li></ul></li></ul></li><li>讲文章结构<ul><li>Overview of Single-Cell Multi-omics Data Modalities section</li><li>the different modalities of single-cell omics data.</li><li>单细胞组学数据的不同模态</li><li>Overview of MDL Techniques<ul><li>多模态分析的深度学习技术</li></ul></li><li>MDL Models for Single-Cell Data Integration<ul><li>the current state-of-the-art MDL models for single-cell data integration</li><li>目前最SOTA的在单细胞数据集成的MDL模型</li></ul></li><li>Discussion and Conclusion<ul><li>the limitations of the current approaches</li><li>future research directions</li><li>conclusions.</li></ul></li></ul></li></ol></blockquote><h2 id="数据概述">数据概述</h2><ul><li><p>scDNA-seq</p></li><li><h2 id="scRNA-seq">scRNA-seq</h2></li><li><p>表观组学</p><ul><li>DNA甲基化</li><li>组蛋白修饰</li><li>染色质可及性</li></ul></li><li><p>蛋白质组学</p></li></ul><p><img src="https://pic.imgdb.cn/item/67108682d29ded1a8cd51275.png" alt=""></p><h2 id="深度学习概述">深度学习概述</h2><p>介绍一下深度学习的几种算法</p><h2 id="单细胞数据整合模型概述">单细胞数据整合模型概述</h2><blockquote><ol><li>第一段，介绍本节内容<ol><li>先说总共identify了多少studies</li><li>给出了一个图（workflow），workflow中包含了第四点中不同的分类</li><li>给出了两个表，一个是这些技术整合的的单细胞多组学数据，另一个是这些技术背后使用的深度学习算法类型</li><li>Then，本节按照 fusion strategy, data type, key task and downstream analysis对这些技术进行分类</li></ol></li></ol></blockquote><p><img src="https://pic.imgdb.cn/item/6710a048d29ded1a8ce73e67.png" alt=""></p><h3 id="data-description">data description</h3><ul><li>data<ul><li>paired<ul><li>不同组学的相同细胞/相同类型细胞</li><li>测序的时候可以同时对一个细胞测出来他的RNA-seq or ATAC这样？</li></ul></li><li>unpaired<ul><li>细胞不匹配</li></ul></li></ul></li><li>integration method<ul><li>horizontal<ul><li>水平，就是不同基因技术/批次之间的配对，主要是消除批次效应</li><li>（自己的理解，感觉不一定对）</li></ul></li><li>vertical<ul><li>相同细胞的不同组学的集成</li><li>主要是paired data</li></ul></li><li>diagonal<ul><li>paired unpaired都能做</li></ul></li></ul></li></ul><p>这篇论文排除了horizontal的方法，因为只有单一模态，而且来自多个source</p><h3 id="model-architecture">model architecture</h3><p>7 types:VAE, AE, encoders, GAN, FCNN, GNN and heterogenous models</p><p>重点是讲了VAE，VAE中采用递进的方式，一个模型比一个模型改进。递进结束之后也可以每一段讲了一个难点，然后讲一个/几个模型是使用什么方法解决的</p><ol><li>scIM(unpaired data):整合了scRNA-seq 和 CyTOF （蛋白）不同技术，整合到相同的潜在空间中，，并通过模拟数据与真实数据验证了细胞匹配的伪时序一致性。但是无法实现一种模态到另一种的预测</li><li>scMM：也是将多种模式集成到一个共享空间，但是使用了‘mixture of experts model’ (MOE)，实现跨模态预测</li><li>Cobolt：目前单模态数据在<strong>质量和数量</strong>上都优于联合模态数据（同时在一个细胞里测多组学，容易有噪声），使用三个encoder，：一种用于 scRNA-seq，一种用于联合模态数据 (scRNA-seq + scATAC-seq)，另一种用于 scATAC-seq</li><li>问题1:之前的MDL模型都是使用<strong>joint embedding</strong>（preserves modality-specific information）。**（提出问题）**问题就是noise or sparsity容易出现在联合模态数据中<ol><li>scMVAE：两个单模态encoder，分别用于scRNA-seq、scATAC-seq data，进行进行<strong>标准化</strong>、<strong>去噪</strong>和<strong>插补</strong>（imputation）。一个多模态encoder，整合不同模态的数据。</li><li>scMVP：使用一些联合学习技术在scMVAE基础上改进，比如特征拼接、a cell-type-guided attention module</li></ol></li><li>问题2:不同的组学数据distribution不同，比如 scATAC-seq相比scRNA-Seq数据量更小、稀疏且变化大，数据不平衡，容易overfit<ol><li>SAILERX</li></ol></li><li>问题3:蛋白数据的技术偏差和噪声<ol><li>totalVI</li></ol></li><li>GLUE</li></ol><p>别的模型结构就不细看了</p><h3 id="key-tasks">key tasks</h3><ol><li><p>modality prediction:从一种模态数据预测到另一种</p></li><li><p>matching</p></li><li><p>joint embedding：联合嵌入，将不同模态投影到同一潜在空间中</p></li></ol><p>很多算法执行不止一项任务</p><h3 id="Fusion-methods">Fusion methods</h3><ol><li><p><strong>早期融合（Early Fusion）</strong></p><ul><li>将不同模态的特征进行拼接，预处理后再输入模型</li></ul></li><li><p><strong>中期融合（Intermediate Fusion）</strong></p><ul><li><p>同质中期融合（Homogeneous Intermediate Fusion）</p></li><li><p>异质中期融合（Heterogeneous Intermediate Fusion）</p></li></ul></li><li><p><strong>晚期融合（Late Fusion）</strong></p><ul><li>单独模态训练，最后整合两个潜在表示的组合</li></ul></li></ol><h3 id="downstream-analysis">downstream analysis</h3><p>整合了单细胞多组学之后的下游分析</p><ol><li>cell type discovery。大部分的工具都会做这块来验证结果。通过比较检测到的细胞类型和注释中的细胞标签的一致性。或者说是进行一些细胞类型发现，不同的亚群</li><li>differential expression analysis (DE)：利用现有的文献支持他们DE分析的结果</li><li>cell trajectory inference：细胞轨迹推断</li><li>cell matching ：联合潜在嵌入有效性的评估</li><li><em>cis</em>-regulatory analysis：顺势调控分析</li></ol><h1>scMDC</h1><p><a href="https://cloud.tencent.com/developer/article/2440296">【论文复现】基于多模态深度学习方法的单细胞多组学数据聚类（【生物信息学】实验二：多组学数据融合：scMDC）</a></p><p>论文：<a href="https://www.nature.com/articles/s41467-022-35031-9">Clustering of single-cell multi-omics data with a multimodal deep learning method</a></p><ul><li>多模态数据之间是互补的<ul><li>CITE-seq ADT protein<ul><li>dropout率较低。<ul><li>能够可靠地量化细胞活动，适合表征细胞功能和类型</li></ul></li><li>由于蛋白质是基因功能的最终产物，ADT数据在功能性描述上更为理想</li><li>缺点<ul><li>只能检测几百种蛋白质</li><li>通常优先包含已知的细胞类型标志物，因此在识别常见细胞类型（如CD4+和CD8+ T细胞）方面表现良好。检测<strong>稀有或少数细胞</strong>类型时<strong>效果较差</strong>。</li></ul></li></ul></li><li>mRNA数据<ul><li>全转录组数据能够捕捉更全面的细胞类型</li><li>高dropout率和稀疏信号</li><li>数据维度高</li></ul></li><li>scATAC-seq数据</li></ul></li><li>不同类型数据之间各自有局限性。通过结合不同类型的数据（如ADT、mRNA、染色质可及性等），提供了更加全面和细致的细胞特征信息</li></ul><h2 id="项目代码结构">项目代码结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">scMDC</span><br><span class="line">│</span><br><span class="line">├── datasets</span><br><span class="line">│   ├── 10XMultiomics_pbmc_3k_granulocyte_plus.h5</span><br><span class="line">│   ├── 10XMultiomics_pbmc_10k_granulocyte_plus.h5</span><br><span class="line">│   ├── CITEseq_GSE100866_anno.h5</span><br><span class="line">│   ├── CITEseq_GSE128639_BMNC_anno.h5</span><br><span class="line">│   ├── CITEseq_PBMC_spector_anno.h5</span><br><span class="line">│   └── CITEseq_realdata_spleen_lymph_206_anno.h5</span><br><span class="line">│</span><br><span class="line">├── MD</span><br><span class="line">│   └── readme.md</span><br><span class="line">│</span><br><span class="line">├── script</span><br><span class="line">│   ├── MDREADME.md</span><br><span class="line">│   ├── run_LRP_script.sh</span><br><span class="line">│   └── run_scMDC_script.sh</span><br><span class="line">│</span><br><span class="line">├── src</span><br><span class="line">│   ├── fig1_.png</span><br><span class="line">│   ├── layers.py</span><br><span class="line">│   ├── LRP.py</span><br><span class="line">│   ├── preprocess.py</span><br><span class="line">│   ├── run_LRP.py</span><br><span class="line">│   ├── run_scMDC.py</span><br><span class="line">│   ├── run_scMDC_batch.py</span><br><span class="line">│   ├── scMDC.py</span><br><span class="line">│   ├── scMDC_batch.py</span><br><span class="line">│   ├── Simulation.R</span><br><span class="line">│   ├── tree.txt</span><br><span class="line">│   └── utils.py</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li><p>数据</p><ul><li><p>X1和Genes</p><ul><li><strong>X1: mRNA计数矩阵</strong> （基因表达，<strong>行</strong>是不同细胞，<strong>列</strong>是不同<strong>基因</strong>）</li><li><strong>Genes</strong>:每个基因的名字 和X1数据配合</li></ul></li><li><p>X2和ADTs</p><ul><li><strong>X2: ADT计数矩阵</strong>（抗体衍生标签数据，CITE-seq，<strong>行</strong>是不同细胞，<strong>列</strong>是不同<strong>抗体</strong>）</li><li>ADTs：抗体的名字 和X2数据配合</li></ul></li><li><p>Y和celltypes</p><ul><li>Y：细胞分组标签 True labels (if exist)</li><li>celltypes不同的细胞类别</li><li>Y和celltypes是等长的，可能一种是celltypes是具体的名字，Y是数字表示</li></ul></li><li><blockquote><p>还有一些别的还没看</p><ol><li>Batch: batch indicator (for multi-batch analysis)</li><li>GenesFromPeaks: feature names in the gene-to-cell matrix mapped from scATAC-seq (only in SMAGE-seq data)</li><li>Barcodes: cell barcodes (if exits)</li></ol></blockquote></li></ul></li><li><p>src 存档代码</p><ul><li><strong><a href="http://layers.py">layers.py</a></strong>：<ul><li>定义了损失函数和辅助层</li></ul></li><li><strong><a href="http://LRP.py">LRP.py</a></strong>：<ul><li>与聚类相关，用来评价聚类之间的效果，聚类边界敏感性分析和解释性分析</li></ul></li><li><strong><a href="http://preprocess.py">preprocess.py</a></strong>：<ul><li>数据预处理的Python脚本，包含数据清洗、归一化等步骤</li></ul></li><li><strong>run_LRP.py</strong>：<ul><li>用于执行 LRP 分析的Python脚本。</li></ul></li><li><strong>run_scMDC.py</strong>：<ul><li>用于执行 ScMDC 分析的Python脚本。</li></ul></li><li><strong>run_scMDC_batch.py</strong>：<ul><li>用于批量执行 ScMDC 分析的Python脚本，适用于处理多个数据集或批次。</li></ul></li><li><strong><a href="http://scMDC.py">scMDC.py</a></strong>：<ul><li>定义了模型网络的结构和核心算法<ul><li>encoder：输入数据X1和X2融合，通过多个全连接层和batch归一化层，提取latent representation</li><li>decoder：重构回原始数据空间，用来重构损失计算</li><li>损失函数<ul><li>ZINB损失：针对RNA-seq过度零值问题</li><li>KL散度：度量潜在空间分布和目标分布之间差异</li><li>聚类损失</li></ul></li><li>聚类机制：结合自编码器和聚类算法，实现端到端聚类</li><li>批次效应校正</li></ul></li></ul></li><li><strong>scMDC_batch.py</strong>：<ul><li>ScMDC 批处理版本的实现文件，支持多批次数据的整合分析。</li></ul></li><li><strong>Simulation.R</strong>：用于模拟数据或进行统计分析的R脚本，可能用于验证算法的性能。</li><li><strong><a href="http://utils.py">utils.py</a></strong>：包含项目中通用的辅助函数和工具类的Python脚本，支持其他模块的功能实现</li></ul></li></ul><blockquote><p>有一个bug，需要修改一下</p><p>x1和x2的数据有一个是float 有一个是Double 得在哪里调整一下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent call last):</span><br><span class="line">  File &quot;run_scMDC.py&quot;, line 145, in &lt;module&gt;</span><br><span class="line">    latent = model.encodeBatch(torch.tensor(adata1.X).to(args.device), torch.tensor(adata2.X).to(args.device))</span><br><span class="line">  File &quot;/home/wzx/scMDC/src/scMDC.py&quot;, line 146, in encodeBatch</span><br><span class="line">    z,_,_,_,_,_,_,_,_ = self.forwardAE(inputs1, inputs2)</span><br><span class="line">  File &quot;/home/wzx/scMDC/src/scMDC.py&quot;, line 116, in forwardAE</span><br><span class="line">    h = self.encoder(x)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1553, in _wrapped_call_impl</span><br><span class="line">    return self._call_impl(*args, **kwargs)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1562, in _call_impl</span><br><span class="line">    return forward_call(*args, **kwargs)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/container.py&quot;, line 219, in forward</span><br><span class="line">    input = module(input)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1553, in _wrapped_call_impl</span><br><span class="line">    return self._call_impl(*args, **kwargs)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/module.py&quot;, line 1562, in _call_impl</span><br><span class="line">    return forward_call(*args, **kwargs)</span><br><span class="line">  File &quot;/home/wzx/miniconda3/envs/scMDC/lib/python3.8/site-packages/torch/nn/modules/linear.py&quot;, line 117, in forward</span><br><span class="line">    return F.linear(input, self.weight, self.bias)</span><br><span class="line">RuntimeError: mat1 and mat2 must have the same dtype, but got Double and Float</span><br><span class="line"></span><br></pre></td></tr></table></figure></blockquote><h1>scMVP</h1><h1>另外几篇综述</h1><ul><li><p>第一篇：</p><ul><li><strong>Multimodal deep learning approaches for single-cell multi-omics data integration</strong></li><li><a href="https://academic.oup.com/bib/article/24/5/bbad313/7256792#418487919">https://academic.oup.com/bib/article/24/5/bbad313/7256792#418487919</a></li></ul></li><li><p>第二篇：</p><ul><li><p>The performance of deep generative models for learning joint embeddings of single-cell multi-omics data</p></li><li><p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9643784/#s1">https://pmc.ncbi.nlm.nih.gov/articles/PMC9643784/#s1</a></p></li></ul></li><li><p>第三篇：</p><ul><li><strong>Application of Deep Learning on Single-Cell RNA Sequencing Data Analysis: A Review</strong></li><li><a href="https://academic.oup.com/gpb/article/20/5/814/7230453">https://academic.oup.com/gpb/article/20/5/814/7230453</a></li></ul></li><li><p>第四篇</p><ul><li>Deep learning applications in single-cell genomics and transcriptomics<br>data analysis</li><li><a href="https://www.sciencedirect.com/science/article/pii/S0753332223008685">https://www.sciencedirect.com/science/article/pii/S0753332223008685</a></li></ul></li></ul><p><a href="https://pmc.ncbi.nlm.nih.gov/articles/PMC9643784/#s1">Cobolt: integrative analysis of multimodal single-cell sequencing data</a></p><p><a href="https://www.sciencedirect.com/science/article/pii/S0753332223008685">Deep learning applications in single-cell genomics and transcriptomics data analysis</a></p><h2 id="introduction-2">introduction</h2><ul><li>打开google</li><li>下载对应的文章到zetero中，然后把文章名字放到括号里</li><li>论文引用要重新检查一些，有些不知道是否区分了a和b<ul><li>![image-20241026020237851](/Users/xuan/Library/Application Support/typora-user-images/image-20241026020237851.png)</li><li>模版和引用顺序问题</li></ul></li></ul><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\section</span>&#123;Introduction&#125;</span><br><span class="line">Single-cell technologies have revolutionized the study of cellular systems, enabling biologists to examine the molecular characteristics of individual cells within a population <span class="keyword">\cite</span>&#123;RNA sequencing: the teenage years&#125;. The shift from traditional bulk sequencing to single-cell sequencing has unveiled previously hidden cellular heterogeneity, revealing functional differences among cell types within the same tissue <span class="keyword">\cite</span>&#123;mRNA-Seq whole-transcriptome analysis of a single cell&#125;. Innovations in technological platforms, such as the integration of microfluidics and high-throughput sequencing, have facilitated the widespread adoption of single-cell sequencing <span class="keyword">\cite</span>&#123;Comprehensive Integration of Single-Cell Data,SCANPY: large-scale single-cell gene expression data analysis.,The dynamics and regulators of cell fate decisions are revealed by pseudotemporal ordering of single cells,Orchestrating single-cell analysis with Bioconductor,Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression&#125;.</span><br><span class="line"></span><br><span class="line">The advent of single-cell multi-omics data has become pivotal in biological research. It allows for an in-depth understanding of cellular heterogeneity and provides insights into cellular development and differentiation processes by tracing cell fate decisions and developmental pathways <span class="keyword">\cite</span>&#123;Statistical single cell multi-omics integration</span><br><span class="line">, Computational strategies for single-cell multi-omics integration, Omics in Systems Biology: Current Progress and Future Outlook,Undisclosed, unmet and neglected challenges in multi-omics studies&#125;. However, performing multi-omics experiments on the same cell remains costly and experimentally challenging, often resulting in studies with relatively small cell numbers <span class="keyword">\cite</span>&#123;Systems Biology and Multi-Omics, Integration strategies of multi-omics data for machine learning analysis&#125;. Additionally, single-cell multi-omics data often suffer from sparsity, noise, differences in sequencing depth, and batch effects, complicating data analysis <span class="keyword">\cite</span>&#123;Multimodal single cell data integration challenge: results and lessons learned&#125;.</span><br><span class="line"></span><br><span class="line">Integrating different modalities of data has thus become essential. Combining genomics, transcriptomics, epigenomics, and proteomics data can provide a more comprehensive understanding of cellular functions that would be unattainable using a single data modality <span class="keyword">\cite</span>&#123;Integrated analysis of multimodal single-cell data, Chromatin Potential Identified by Shared Single-Cell Profiling of RNA and Chromatin&#125;. Nonetheless, data integration faces significant challenges, including high dimensionality, heterogeneity, technical noise, and data sparsity <span class="keyword">\cite</span>&#123;Multimodal single cell data integration challenge: results and lessons learned&#125;.</span><br><span class="line"></span><br><span class="line">Deep learning has emerged as a powerful tool in bioinformatics, offering new methodologies to handle complex biological data <span class="keyword">\cite</span>&#123;Machine learning applications in genetics and genomics, Using machine learning approaches for multi-omics data analysis: A review&#125;. In genomics, deep learning has been utilized for variant detection and functional prediction; in transcriptomics, for analyzing gene expression patterns and constructing gene regulatory networks; and in epigenomics, for predicting DNA methylation and chromatin states <span class="keyword">\cite</span>&#123;Deep Multimodal Learning: A Survey on Recent Advances and Trends&#125;.</span><br><span class="line"></span><br><span class="line">Multimodal deep learning presents several advantages, such as automatic feature extraction without the need for manual feature engineering, enabling the automatic learning of deep patterns within data <span class="keyword">\cite</span>&#123;Robust single-cell matching and multimodal analysis using shared and distinct features&#125;. Deep learning models, through multilayer neural networks, can capture complex nonlinear relationships, thus handling high-dimensional data effectively <span class="keyword">\cite</span>&#123;Computational strategies for single-cell multi-omics integration. , Deep learning in bioinformatics.&#125;. Moreover, deep learning enables cross-modal information fusion, integrating different types of data to enhance predictive capabilities <span class="keyword">\cite</span>&#123;Computational strategies for single-cell multi-omics integration. , Deep learning in bioinformatics.&#125;.</span><br><span class="line"></span><br><span class="line">However, applying deep learning to single-cell data integration also presents challenges. Overfitting can occur during model training, particularly with high-dimensional, imbalanced single-cell multi-omics data <span class="keyword">\cite</span>&#123;A roadmap for multi-omics data integration using deep learning&#125;. Data sparsity is another issue, as single-cell multi-omics data often contain numerous missing values <span class="keyword">\cite</span>&#123;A Review of Integrative Imputation for Multi-Omics Datasets&#125;. Furthermore, there is a lack of consensus on the best methods for integrating single-cell multi-omics data using deep learning techniques, making it challenging to compare results across different studies <span class="keyword">\cite</span>&#123;Computational methods for single-cell multi-omics integration and alignment. &#125;. Despite these challenges, the application of deep learning in single-cell multi-omics data integration holds great potential, and ongoing research is improving these methods and making them more accessible to researchers <span class="keyword">\cite</span>&#123;Multimodal deep learning approaches for single-cell multi-omics data integration&#125;.</span><br><span class="line"></span><br><span class="line">This review aims to provide a comprehensive overview of the current state-of-the-art deep learning models for single-cell multi-omics data integration. We categorize existing approaches based on model architecture, fusion strategy, key integration tasks, and downstream biological analyses. By addressing the limitations of current methods and highlighting future research directions, we hope to advance the application of deep learning in single-cell multi-omics integration.</span><br></pre></td></tr></table></figure><h2 id="data-overview">data overview</h2><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\section</span>&#123;Overview of Single-Cell Multi-Omics Data Modalities&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Single-Cell Genomics Data&#125;</span><br><span class="line"></span><br><span class="line">Single-cell DNA sequencing (scDNA-seq) has emerged as a pivotal tool for identifying copy number variations, somatic mutations, and tracing cell lineages at the single-cell level <span class="keyword">\cite</span>&#123;Methods for copy number aberration detection from single-cell DNA-sequencing data&#125;. To facilitate scDNA-seq, various whole-genome amplification techniques have been developed, including degenerate oligonucleotide-primed PCR (DOP-PCR), multiple displacement amplification (MDA), and multiple annealing and looping-based amplification cycles (MALBAC) <span class="keyword">\cite</span>&#123;Single-cell whole-genome amplification and sequencing: methodology and applications&#125;. MDA employs <span class="built_in">$</span><span class="keyword">\phi</span><span class="built_in">$</span>29 DNA polymerase for isothermal amplification, enhancing efficiency but potentially introducing bias due to preferential amplification <span class="keyword">\cite</span>&#123;Single-cell genomics: coming of age&#125;. MALBAC combines the advantages of PCR and MDA, reducing amplification bias and providing more uniform coverage across the genome <span class="keyword">\cite</span>&#123;Single Cell Transcriptome Amplification with MALBAC&#125;.</span><br><span class="line"></span><br><span class="line">These amplification technologies have enabled applications such as tracking cancer clones to reveal tumor heterogeneity and evolution <span class="keyword">\cite</span>&#123;Single-Cell Transcriptomics Meets Lineage Tracing,Annual Review of Genomics and Human Genetics ,Single-cell sequencing techniques from individual to multiomics analyses&#125;, as well as identifying rare cell types by detecting genomic variations in minor cell populations <span class="keyword">\cite</span>&#123;urrent Progresses of Single Cell DNA Sequencing in Breast Cancer Research&#125;. Despite these advancements, scDNA-seq data often exhibit sparsity and high noise levels due to technical artifacts introduced during amplification <span class="keyword">\cite</span>&#123;Methods for copy number aberration detection from single-cell DNA-sequencing data&#125;. Amplification bias and uneven coverage remain significant challenges, leading to non-uniform sequencing depth across genomic regions <span class="keyword">\cite</span>&#123;Single-cell whole-genome amplification and sequencing: methodology and applications., Single-cell genomics: coming of age&#125;.</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Single-Cell Transcriptomics Data&#125;</span><br><span class="line"></span><br><span class="line">Single-cell RNA sequencing (scRNA-seq) enables the measurement of gene expression levels in individual cells, offering high-resolution insights into cellular diversity and heterogeneity <span class="keyword">\cite</span>&#123;Single-cell transcriptomics: current methods and challenges in data acquisition and analysis.&#125;. Full-length transcript sequencing methods, such as Smart-seq and its enhanced version Smart-seq2, capture complete transcripts, allowing the detection of alternative splicing events, allele-specific expression, and lowly expressed genes <span class="keyword">\cite</span>&#123;mRNA-seq whole-transcriptome analysis of a single cell. ,Beyond bulk: a review of single cell transcriptomics methodologies and applications,Single-cell RNA sequencing technologies and bioinformatics pipelines&#125;. Smart-seq2 improves reverse transcription efficiency and amplification sensitivity, increasing gene detection depth <span class="keyword">\cite</span>&#123;SCANPY: large-scale single-cell gene expression data analysis,The dynamics and regulators of cell fate decisions are revealed by pseudotemporal ordering of single cells,Comprehensive Integration of Single-Cell Data&#125;.</span><br><span class="line"></span><br><span class="line">In contrast, high-throughput methods focusing on the 3&#x27; end of transcripts, such as 10x Chromium, Drop-seq, and inDrop, enable the profiling of thousands of cells simultaneously at a lower cost <span class="keyword">\cite</span>&#123;Single-Cell RNA-Seq Technologies and Related Computational Data Analysis&#125;. 10x Chromium utilizes barcoded microbeads to achieve massive parallelization. Drop-seq employs microfluidics to encapsulate single cells and primers in droplets <span class="keyword">\cite</span>&#123;Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets&#125;, while inDrop enhances sequencing efficiency by using hydrogel beads with cleavable primers <span class="keyword">\cite</span>&#123;The dynamics of gene expression in vertebrate embryogenesis at single-cell resolution&#125;.</span><br><span class="line"></span><br><span class="line">scRNA-seq data are high-dimensional and sparse, with gene expression matrices containing a large proportion of zero values due to the low amount of mRNA in single cells and stochastic gene expression <span class="keyword">\cite</span>&#123;Graph Convolutional Network-based Method for Clustering Single-cell RNA-seq Data&#125;. Batch effects and technical noise arising from different experimental conditions and platforms introduce systematic biases that complicate data analysis.</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Single-Cell Epigenomics Data&#125;</span><br><span class="line"></span><br><span class="line">Single-cell epigenomics focuses on genome-wide epigenetic modifications, such as DNA methylation, histone modifications, and chromatin accessibility <span class="keyword">\cite</span>&#123;The Mammalian Epigenome，Advances in epigenetics link genetics to the environment and disease&#125;. Techniques like single-cell bisulfite sequencing (scBS-seq) enable single-base resolution mapping of DNA methylation by converting unmethylated cytosines to uracil <span class="keyword">\cite</span>&#123;Single-cell genome-wide bisulfite sequencing for assessing epigenetic heterogeneity&#125;. Single-cell reduced representation bisulfite sequencing (scRRBS-seq) combines enzymatic digestion and bisulfite treatment to focus on CpG-rich regions, reducing sequencing costs while maintaining informative methylation profiling <span class="keyword">\cite</span>&#123;Smart-RRBS for single-cell methylome and transcriptome analysis&#125;.</span><br><span class="line"></span><br><span class="line">Chromatin accessibility can be assessed using methods such as single-cell assay for transposase-accessible chromatin using sequencing (scATAC-seq) and single-cell DNase-seq. scATAC-seq employs a transposase to insert sequencing adapters into accessible chromatin regions, marking sites of regulatory activity <span class="keyword">\cite</span>&#123;Single-cell chromatin accessibility reveals principles of regulatory variation&#125;. scDNase-seq uses DNase I to cleave open chromatin, revealing active regulatory elements <span class="keyword">\cite</span>&#123;Genome-wide detection of DNase I hypersensitive sites in single cells and FFPE tissue samples&#125;.</span><br><span class="line"></span><br><span class="line">Single-cell epigenomic data often suffer from sparsity and noise due to low signal intensity at the single-cell level. Limited coverage per cell restricts the detection of regulatory elements across the genome, posing challenges for comprehensive analysis <span class="keyword">\cite</span>&#123;Multimodal single cell data integration challenge: results and lessons learned&#125;.</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Single-Cell Proteomics Data&#125;</span><br><span class="line"></span><br><span class="line">Single-cell proteomics investigates the protein content of individual cells, analyzing their roles and interactions <span class="keyword">\cite</span>&#123;Single-Cell Proteomics&#125;. Mass cytometry (CyTOF) combines flow cytometry with mass spectrometry by using metal isotope-labeled antibodies to detect cellular proteins. This method allows high-parameter, multiplexed protein detection without the spectral overlap issues common in fluorescence-based techniques. CyTOF has been applied to identify immune cell subsets, providing deep insights into immune system complexity .</span><br><span class="line"></span><br><span class="line">Flow cytometry (FACS) utilizes fluorescently labeled antibodies to detect surface and intracellular antigens, enabling cell sorting and quantitative analysis. While FACS offers higher sensitivity, it is limited in the number of parameters that can be simultaneously measured due to spectral overlap. Analyzing and visualizing high-dimensional proteomics data is complex due to the multitude of measured parameters. Variability in antibody affinities and labeling efficiencies affects data comparability, making standardization and quantitative analysis challenging.</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Joint-Modality Single-Cell Multi-Omics Data&#125;</span><br><span class="line"></span><br><span class="line">Recent advancements have led to technologies capable of measuring multiple omics modalities within the same single cell, providing a more comprehensive view of cellular states <span class="keyword">\cite</span>&#123;Single-cell multimodal omics: the power of many，Single-cell multiomics: technologies and data analysis methods&#125;. Techniques like scM<span class="built_in">&amp;</span>T-seq simultaneously profile DNA methylation and transcriptomes, revealing correlations between epigenetic modifications and gene expression . SHARE-seq measures chromatin accessibility and gene expression concurrently, facilitating the construction of gene regulatory networks. SNARE-seq combines mRNA sequencing with chromatin accessibility profiling for comprehensive regulatory analysis <span class="keyword">\cite</span>&#123;High-throughput sequencing of the transcriptome and chromatin accessibility in the same cell&#125;.</span><br><span class="line"></span><br><span class="line">Joint-modality data provide extensive information across different omics layers at the single-cell level, enhancing the understanding of cellular functions and states. By linking modalities within the same cell, these methods reduce the impact of cellular heterogeneity on data integration. However, the complexity and volume of joint-modality data pose significant computational challenges, requiring advanced analytical methods and substantial computational resources. Effective alignment and integration of heterogeneous cross-modal data necessitate the development of robust algorithms and models.</span><br></pre></td></tr></table></figure><h2 id="deep-learning-overview">deep learning overview</h2><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">\section</span>&#123;Deep Learning Techniques in Single-Cell Multi-Omics Integration&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsection</span>&#123;Common Multimodal Deep Learning Models&#125;</span><br><span class="line"></span><br><span class="line">Deep learning has emerged as a potent tool for analyzing high-throughput biological data, capable of capturing complex non-linear and cross-modal relationships <span class="keyword">\cite</span>&#123;Multimodal deep learning for biomedical data fusion: a review&#125;. In the context of single-cell multi-omics integration, several deep learning architectures have been employed to address the challenges posed by high-dimensional and heterogeneous data.</span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsubsection</span>&#123;Fully Connected Neural Networks (FCNN)&#125;</span><br><span class="line"></span><br><span class="line">Fully connected neural networks (FCNNs), also known as deep feed-forward neural networks (DFNNs), are the most fundamental architecture in deep learning, consisting of multiple layers where each neuron in one layer is connected to every neuron in the next layer. FCNNs leverage large sets of trainable weights and non-linear activation functions to capture underlying complex patterns in data . Training is typically performed using backpropagation to minimize prediction errors by adjusting model weights <span class="keyword">\cite</span>&#123;Prediction of Alzheimer&#x27;s disease based on deep neural network by integrating gene expression and DNA methylation dataset&#125;.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsubsection</span>&#123;Convolutional Neural Networks (CNN)&#125;</span><br><span class="line"></span><br><span class="line">Convolutional neural networks (CNNs) are specialized neural networks designed to process data with a grid-like topology, such as images, by employing convolutional layers to extract local features. A typical CNN architecture includes convolutional layers for feature extraction, pooling layers for dimensionality reduction, and fully connected layers for integrating global information.</span><br><span class="line"></span><br><span class="line">Although single-cell omics data do not inherently possess a grid structure, CNNs have been adapted for their analysis by transforming the data appropriately.Islam <span class="keyword">\textit</span>&#123;et al.&#125; utilized a deep CNN model to integrate copy number alterations and gene expression data for classifying breast cancer subtypes <span class="keyword">\cite</span>&#123;An integrative deep learning framework for classifying molecular subtypes of breast cancer&#125;. </span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsubsection</span>&#123;Recurrent Neural Networks (RNN)&#125;</span><br><span class="line"></span><br><span class="line">Recurrent neural networks (RNNs) are designed for processing sequential data by maintaining a hidden state that captures information from previous inputs, making them suitable for modeling temporal dependencies. However, traditional RNNs face challenges such as vanishing or exploding gradients during training .</span><br><span class="line"></span><br><span class="line">To overcome these issues, variants like long short-term memory networks (LSTMs) and gated recurrent units (GRUs) have been developed, incorporating gating mechanisms to regulate information flow and mitigate gradient problems. In multimodal omics integration, Bichindaritz <span class="keyword">\textit</span>&#123;et al.&#125; used LSTMs to predict breast cancer survival rates by integrating gene expression and DNA methylation data <span class="keyword">\cite</span>&#123;Integrative survival analysis of breast cancer with gene expression and DNA methylation data&#125;. </span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsubsection</span>&#123;Autoencoders (AE) and Variants&#125;</span><br><span class="line"></span><br><span class="line">Autoencoders (AEs) are neural networks comprising an encoder and a decoder, used primarily for unsupervised learning tasks such as dimensionality reduction and feature extraction. The encoder compresses input data into a lower-dimensional latent space, while the decoder reconstructs the original data from this latent representation.</span><br><span class="line"></span><br><span class="line">Variational autoencoders (VAEs) are a generative extension of AEs that model the latent space as a probability distribution, allowing for the generation of new data samples <span class="keyword">\cite</span>&#123;A versatile and scalable single-cell data integration algorithm based on domain-adversarial and variational approximation&#125;. VAEs introduce a regularization term in the loss function, specifically the Kullback–Leibler divergence, to encourage the learned latent distribution to match a prior distribution. The loss function of a VAE is defined as:</span><br><span class="line"></span><br><span class="line"><span class="keyword">\begin</span>&#123;equation&#125;</span><br><span class="line"><span class="keyword">\mathcal</span>&#123;L&#125; = <span class="keyword">\mathbb</span>&#123;E&#125;<span class="built_in">_</span>&#123;q<span class="built_in">_</span>&#123;<span class="keyword">\phi</span>&#125;(z|x)&#125;[<span class="keyword">\log</span> p<span class="built_in">_</span>&#123;<span class="keyword">\theta</span>&#125;(x|z)] - <span class="keyword">\mathrm</span>&#123;KL&#125;(q<span class="built_in">_</span>&#123;<span class="keyword">\phi</span>&#125;(z|x) <span class="keyword">\|</span> p(z)),</span><br><span class="line"><span class="keyword">\end</span>&#123;equation&#125;</span><br><span class="line"></span><br><span class="line">where <span class="keyword">\(</span> q<span class="built_in">_</span>&#123;<span class="keyword">\phi</span>&#125;(z|x) <span class="keyword">\)</span> represents the encoder&#x27;s approximate posterior distribution, <span class="keyword">\(</span> p<span class="built_in">_</span>&#123;<span class="keyword">\theta</span>&#125;(x|z) <span class="keyword">\)</span> denotes the decoder&#x27;s likelihood function, and <span class="keyword">\(</span> p(z) <span class="keyword">\)</span> is the prior distribution over latent variables.</span><br><span class="line"></span><br><span class="line">VAEs are extensively utilized in single-cell data analysis for clustering, dimensionality reduction, and imputation tasks due to their ability to capture complex, non-linear relationships. Guo <span class="keyword">\textit</span>&#123;et al.&#125; applied denoising autoencoders to multi-omics ovarian cancer data to identify cancer subtypes <span class="keyword">\cite</span>&#123;Deep learning-based ovarian cancer subtypes identification using multi-omics data&#125;. Ronen <span class="keyword">\textit</span>&#123;et al.&#125; used stacked VAEs to measure similarities between colorectal tumors and cancer cell lines <span class="keyword">\cite</span>&#123;Evaluation of colorectal cancer subtypes and cell lines using deep learning&#125;. In single-cell multi-omics integration, VAEs are particularly prominent because of their capacity to model the joint distribution of multiple data modalities effectively.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">\subsubsection</span>&#123;Generative Adversarial Networks (GAN)&#125;</span><br><span class="line"></span><br><span class="line">Generative adversarial networks (GANs) consist of a generator and a discriminator network engaged in a minimax game, where the generator aims to produce data indistinguishable from real data, and the discriminator attempts to differentiate between real and generated samples <span class="keyword">\cite</span>&#123;Sparsity-Penalized Stacked Denoising Autoencoders for Imputing Single-Cell RNA-seq Data&#125;. GANs are powerful in generating realistic synthetic data without assuming any prior distribution, making them flexible for various applications.</span><br><span class="line"></span><br><span class="line">In the realm of single-cell multi-omics integration, GANs have been employed for data augmentation, imputation, and alignment of biological manifolds.Despite their strengths, GANs present challenges in training stability due to issues like mode collapse and vanishing gradients <span class="keyword">\cite</span>&#123;Droplet scRNA-seq is not zero-inflated&#125;. Variants such as Wasserstein GANs (WGANs) have been proposed to address these problems and improve convergence.</span><br></pre></td></tr></table></figure><h2 id="DL-in-single-cell-multi-omics">DL in single-cell multi-omics</h2><p>这里得给出一个大的表格</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">\section&#123;Deep Learning Models for Single-Cell Data Integration&#125;</span><br><span class="line"></span><br><span class="line">\subsection&#123;Data Description&#125;</span><br><span class="line"></span><br><span class="line">In the field of single-cell multi-omics data integration, datasets are generally categorized into \textbf&#123;paired&#125; and \textbf&#123;unpaired&#125; data types . Paired data consist of multiple modalities measured from the same cells, such as scRNA-seq and scATAC-seq obtained simultaneously, serving as anchors for integration. Unpaired data, on the other hand, are collected from different cells without direct correspondence, eliminating the need for anchor information \cite&#123;Integrated analysis of multimodal single-cell data&#125;.</span><br><span class="line"></span><br><span class="line">Based on the pairing and anchor information, data integration methods are divided into \textbf&#123;vertical integration&#125; and \textbf&#123;diagonal integration&#125;. Vertical integration leverages paired cells as anchors to align different modalities directly. Diagonal integration bypasses the need for pairing information by directly integrating different modalities, assuming an underlying low-dimensional structure that links them \cite&#123;Chromatin Potential Identified by Shared Single-Cell Profiling of RNA and Chromatin&#125;.</span><br><span class="line"></span><br><span class="line">Common datasets and technological platforms used in this area include CITE-seq, SHARE-seq. The CITE-seq dataset combines gene expression with surface protein data, enabling simultaneous analysis of transcriptomic and proteomic information at the single-cell level . SHARE-seq jointly measures the transcriptome and chromatin accessibility, providing insights into the relationship between gene expression and epigenetic regulation. SNARE-seq simultaneously profiles mRNA and chromatin accessibility, facilitating an in-depth study of the interplay between gene expression and chromatin state.</span><br><span class="line"></span><br><span class="line">\subsection&#123;Model Architecture Classification&#125;</span><br><span class="line"></span><br><span class="line">Researchers have proposed various deep learning models for integrating single-cell multi-omics data, which can be classified into Variational Autoencoder (VAE)-based models, Autoencoder (AE)-based models, Encoder models, Generative Adversarial Network (GAN)-based models, and Other models.</span><br><span class="line"></span><br><span class="line">\subsubsection&#123;VAE-Based Models&#125;</span><br><span class="line"></span><br><span class="line">SCIM is a model utilizing the VAE framework to integrate scRNA-seq and CyTOF data \cite&#123;SCIM: universal single-cell matching with unpaired feature sets&#125;. It employs dual encoders and decoders along with a discriminator, achieving joint embedding of different modalities through adversarial training. Specifically, SCIM constructs independent encoders and decoders for each modality and uses a discriminator to align the latent representations in a shared space, enabling data integration.</span><br><span class="line"></span><br><span class="line">scMM also adopts a VAE architecture, implementing a Mixture-of-Experts (MoE) model to factorize the joint representation \cite&#123;A mixture-of-experts deep generative model for integrated analysis of single-cell multiomics data&#125;. It independently trains encoders for each modality and combines the posterior distribution parameters using the MoE. This approach avoids over-reliance on a single modality, achieves balanced integration, and allows for cross-modal prediction .</span><br><span class="line"></span><br><span class="line">Cobolt introduces multiple encoders and decoders within the VAE framework, expanding its applicability to both single-modality and joint-modality data \cite&#123;Cobolt: integrative analysis of multimodal single-cell sequencing data.&#125;. It constructs encoders for scRNA-seq, scATAC-seq, and joint-modality data, projecting different modalities into a shared latent space through joint posterior distributions. This is particularly significant given the current abundance of single-modality over joint-modality data .</span><br><span class="line"></span><br><span class="line">scMVAE addresses the sparsity of joint-modality data by improving the quality of joint embeddings \cite&#123;Deep-joint-learning analysis model of single cell transcriptome and open chromatin accessibility data.&#125;. It employs multiple joint learning strategies, including using joint and single-modality encoders, and various methods such as the product of posteriors and neural network-based joint space learning. These strategies enhance the accuracy of joint embeddings and capture richer biological variation.</span><br><span class="line"></span><br><span class="line">scMVP incorporates attention mechanisms within the VAE architecture to capture inter-modal correlations, improving the precision of joint embeddings \cite&#123;A deep generative model for multi-view profiling of single-cell RNA-seq and ATAC-seq data.&#125;. Specifically, scMVP uses multi-head self-attention modules in the encoders and decoders to focus on key features, and employs cycle consistency loss to stabilize the shared latent space.</span><br><span class="line"></span><br><span class="line">\subsubsection&#123;AE-Based Models&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BABEL employs dual autoencoders with a shared latent space to enable modality translation at the single-cell level \cite&#123;BABEL enables cross-modality translation between multiomic profiles at single-cell resolution&#125;. Independent encoders learn from each modality and project them into a shared latent space, followed by decoders that reconstruct the original modalities, facilitating cross-modal prediction.</span><br><span class="line"></span><br><span class="line">scMDC aims to enhance clustering accuracy by capturing inter-modal information through joint embeddings \cite&#123;Clustering of single-cell multi-omics data with a multimodal deep learning method&#125;. It uses a multimodal autoencoder to learn a shared latent representation from concatenated modality data, leading to more precise identification of cell subpopulations.</span><br><span class="line"></span><br><span class="line">\subsubsection&#123;Encoder Models&#125;</span><br><span class="line"></span><br><span class="line">SMILE leverages contrastive learning to maximize mutual information between different modalities, integrating single-cell multi-omics data \cite&#123;SMILE: mutual information learning for integration of single-cell omics data &#125;. It has two variants, pSMILE and mpSMILE, which adapt to different data scenarios by adjusting modality weights to obtain more discriminative representations.</span><br><span class="line"></span><br><span class="line">scJoint utilizes a transfer learning approach to project scRNA-seq labels onto scATAC-seq data, achieving unsupervised integration without requiring paired data \cite&#123;scJoint integrates atlas-scale single-cell RNA-seq and ATAC-seq data with transfer learning.&#125;. By employing two loss functions, scJoint maximizes alignment between modalities in the joint embedding space while preserving cell-type information.</span><br><span class="line"></span><br><span class="line">\subsubsection&#123;GAN-Based Models&#125;</span><br><span class="line"></span><br><span class="line">Portal is designed for large-scale data integration with good scalability \cite&#123; Adversarial domain translation networks for integrating large-scale atlas-level single-cell datasets. &#125;. It introduces domain translation networks consisting of encoders, generators, and discriminators, achieving data alignment in a shared latent space through adversarial training and regularization.</span><br><span class="line"></span><br><span class="line">\subsection&#123;Key Tasks of the Models&#125;</span><br><span class="line"></span><br><span class="line">These deep learning models primarily address key tasks in single-cell data integration, including modality prediction, modality matching, and joint embedding.</span><br><span class="line"></span><br><span class="line">Modality prediction involves predicting data in one modality based on another, facilitating data completion and imputation of missing values . For instance, MAGAN and k-Coupled AE are capable of modality prediction, filling gaps in datasets.</span><br><span class="line"></span><br><span class="line">Modality matching aims to align corresponding cells across different modalities, validating the effectiveness of joint embeddings and enhancing data integration. Models like scMoGNN and SMILE focus on this task, improving integration accuracy by matching cells in unpaired datasets.</span><br><span class="line"></span><br><span class="line">Joint embedding projects multi-modal data into a shared low-dimensional space, capturing inter-modal correlations and facilitating downstream analyses. Most models, such as scMM and Cobolt, strive to achieve effective joint embeddings as a foundation for comprehensive integration.</span><br><span class="line"></span><br><span class="line">\subsection&#123;Fusion Strategies&#125;</span><br><span class="line"></span><br><span class="line">Deep learning models employ various fusion strategies for integrating multi-modal data, including early fusion, intermediate fusion, and late fusion.</span><br><span class="line"></span><br><span class="line">Early fusion involves directly concatenating features from different modalities as input to the model. This method is simple and straightforward but may lead to high-dimensional inputs and increased computational complexity. Models like scMVAE and totalVI utilize this strategy.</span><br><span class="line"></span><br><span class="line">Intermediate fusion fuses information from different modalities within the hidden layers of the model and can be further divided into homogeneous fusion and heterogeneous fusion .</span><br><span class="line"></span><br><span class="line">Late fusion trains separate models for each modality and fuses the outputs at the decision level. This strategy offers flexibility and allows for modality-specific optimization but may not fully capture inter-modal interactions. Models like k-Coupled AE and MIRA employ late fusion.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>假设你是一个生物信息学专家，你的研究领域是利用深度学习来进行单细胞多组学的整合，你要为这个领域撰写一篇综述。目前你已经草拟出了一个框架，并参考了四篇相似领域的综述。现在需要撰写的是单细胞多组学中的深度学习模型概述部分，也就是相关的深度学习模型的介绍。，按照以下详细的大纲撰写你自己综述的“深度学习模型概述”部分。写作过程中，每句话末尾需要标注引用，格式为参考的第几篇的第几个引用（例如 [1]，[2] 等）。<br>注意这里因为字数原因原本第三篇被删除，所以这里没有第三篇的内容，但是依然保留第四篇，注意。</p><p>框架：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line">## 单细胞数据整合的多模态深度学习模型</span><br><span class="line"></span><br><span class="line">### 4.1 数据描述</span><br><span class="line"></span><br><span class="line">- 数据集的类型：</span><br><span class="line">  - 配对数据：同一细胞的多模态数据，可作为锚点。</span><br><span class="line">  - 非配对数据：不同细胞的多模态数据，无需锚点。</span><br><span class="line">- 数据整合方式：</span><br><span class="line">  - 垂直整合：利用配对细胞进行整合。</span><br><span class="line">  - 对角整合：无需配对信息，直接整合不同模态的数据。</span><br><span class="line">- 常用的数据集和技术平台：</span><br><span class="line">  - CITE-seq数据集：结合基因表达和表面蛋白质数据。</span><br><span class="line">  - SHARE-seq数据集：联合测量转录组和染色质可及性。</span><br><span class="line">  - SNARE-seq数据集：同时测量mRNA和染色质可及性。</span><br><span class="line"></span><br><span class="line">### 4.2 模型架构分类</span><br><span class="line"></span><br><span class="line">#### 4.2.1 基于变分自编码器（VAE）的模型</span><br><span class="line"></span><br><span class="line">- SCIM：</span><br><span class="line">  - 模型结构：双编码器和双解码器，加上判别器。</span><br><span class="line">  - 特点：利用对抗训练实现不同模态的联合嵌入。</span><br><span class="line">- scMM：</span><br><span class="line">  - 模型结构：混合专家模型，实现联合表示的因式分解。</span><br><span class="line">  - 优势：能够进行跨模态预测。</span><br><span class="line">- Cobolt：</span><br><span class="line">  - 特点：处理单模态和联合模态数据，扩大了适用范围。</span><br><span class="line">  - 创新点：引入了多编码器和解码器的架构。</span><br><span class="line">- scMVAE：</span><br><span class="line">  - 解决问题：针对联合模态数据的稀疏性，改进了联合嵌入的质量。</span><br><span class="line">  - 方法：引入了多种联合学习策略。</span><br><span class="line">- scMVP：</span><br><span class="line">  - 改进点：通过注意力机制捕获模态间的相关性。</span><br><span class="line">  - 优势：提高了联合嵌入的准确性。</span><br><span class="line"></span><br><span class="line">#### 4.2.2 基于自编码器（AE）的模型</span><br><span class="line"></span><br><span class="line">- k-Coupled AE：</span><br><span class="line">  - 概念：多代理自编码器，相互协作学习。</span><br><span class="line">  - 功能：实现跨模态翻译和数据整合。</span><br><span class="line">- BABEL：</span><br><span class="line">  - 架构：双自编码器，共享潜在空间。</span><br><span class="line">  - 应用：在单细胞水平上实现模态间的转换。</span><br><span class="line">- scMDC：</span><br><span class="line">  - 目标：提高聚类的准确性。</span><br><span class="line">  - 策略：通过联合嵌入捕获模态间的信息。</span><br><span class="line"></span><br><span class="line">#### 4.2.3 编码器模型</span><br><span class="line"></span><br><span class="line">- SMILE：</span><br><span class="line">  - 方法：对比学习，最大化不同模态间的互信息。</span><br><span class="line">  - 变体：pSMILE和mpSMILE，适应不同的数据情况。</span><br><span class="line">- scJoint：</span><br><span class="line">  - 方法：迁移学习，将scRNA-seq的标签信息转移到scATAC-seq。</span><br><span class="line">  - 优势：无需配对数据，实现了无监督的整合。</span><br><span class="line"></span><br><span class="line">#### 4.2.4 基于生成对抗网络（GAN）的模型</span><br><span class="line"></span><br><span class="line">- MAGAN：</span><br><span class="line">  - 策略：流形对齐，通过双GAN实现模态间的映射。</span><br><span class="line">  - 应用：整合CyTOF和scRNA-seq数据。</span><br><span class="line">- Portal：</span><br><span class="line">  - 特点：适用于大规模数据，具有良好的可扩展性。</span><br><span class="line">  - 创新点：引入了域翻译网络，实现了数据的对齐。</span><br><span class="line"></span><br><span class="line">#### 4.2.5 其他模型</span><br><span class="line"></span><br><span class="line">- scMoGNN：</span><br><span class="line">  - 方法：利用GNN捕获细胞和特征之间的高阶交互。</span><br><span class="line">  - 优势：整合了结构信息，提高了模型性能。</span><br><span class="line">- sciCAN：</span><br><span class="line">  - 架构：编码器结合GAN，无需细胞锚点。</span><br><span class="line">  - 功能：实现跨模态的对齐和翻译。</span><br><span class="line">- scDART：</span><br><span class="line">  - 特点：保留细胞轨迹信息，适用于连续的细胞状态。</span><br><span class="line">  - 方法：引入了扩散距离，保持了细胞间的拓扑结构。</span><br><span class="line"></span><br><span class="line">### 4.3 模型的关键任务</span><br><span class="line"></span><br><span class="line">- 模态预测：</span><br><span class="line">  - 定义：根据一种模态的数据预测另一种模态的数据。</span><br><span class="line">  - 应用：填补缺失数据，实现数据的补全。</span><br><span class="line">- 模态匹配：</span><br><span class="line">  - 定义：在不同模态之间匹配对应的细胞。</span><br><span class="line">  - 应用：验证联合嵌入的有效性，促进数据的整合。</span><br><span class="line">- 联合嵌入：</span><br><span class="line">  - 定义：将多模态数据投影到共享的低维空间。</span><br><span class="line">  - 优势：捕获模态间的相关性，便于下游分析。</span><br><span class="line"></span><br><span class="line">### 4.4 融合策略</span><br><span class="line"></span><br><span class="line">- 早期融合：</span><br><span class="line">  - 方法：直接将不同模态的特征拼接作为模型的输入。</span><br><span class="line">  - 优点：简单直观，易于实现。</span><br><span class="line">  - 缺点：可能导致维度过高，增加计算复杂度。</span><br><span class="line">  - 应用实例：scMVAE、totalVI、SCALEX。</span><br><span class="line">- 中间融合：</span><br><span class="line">  - 方法：在模型的隐藏层中融合不同模态的信息。</span><br><span class="line">  - 同构融合：</span><br><span class="line">    - 定义：使用相同的网络结构处理不同模态的数据。</span><br><span class="line">    - 应用实例：SCIM、scMM、Cobolt。</span><br><span class="line">  - 异构融合：</span><br><span class="line">    - 定义：使用不同的网络结构处理不同模态的数据。</span><br><span class="line">    - 应用实例：crossmodal-AE、sciCAN。</span><br><span class="line">- 后期融合：</span><br><span class="line">  - 方法：分别训练不同模态的模型，最后融合输出结果。</span><br><span class="line">  - 优点：灵活，可针对每个模态优化模型。</span><br><span class="line">  - 缺点：可能无法充分捕获模态间的交互。</span><br><span class="line">  - 应用实例：k-Coupled AE、MIRA。</span><br><span class="line"></span><br><span class="line">### 4.5 下游分析</span><br><span class="line"></span><br><span class="line">- 细胞类型发现：</span><br><span class="line">  - 方法：利用聚类和降维技术识别细胞亚群。</span><br><span class="line">  - 评估指标：调整兰德指数、归一化互信息、轮廓系数等。</span><br><span class="line">- 差异表达分析（DE）：</span><br><span class="line">  - 目的：识别不同细胞类型或状态之间的差异基因。</span><br><span class="line">  - 方法：统计检验和多重检验校正。</span><br><span class="line">- 细胞轨迹推断：</span><br><span class="line">  - 目标：重建细胞发育或分化的动态过程。</span><br><span class="line">  - 方法：拟时序分析、主成分分析、马尔科夫链等。</span><br><span class="line">- 细胞匹配：</span><br><span class="line">  - 目的：验证联合嵌入空间中细胞的对应关系。</span><br><span class="line">  - 评价指标：k近邻准确率、余弦相似度、邻域重叠分数等。</span><br><span class="line">- 顺式调控分析：</span><br><span class="line">  - 目标：识别基因调控元件和调控网络。</span><br><span class="line">  - 方法：结合scATAC-seq数据，预测转录因子结合位点，构建调控网络。</span><br></pre></td></tr></table></figure><p>四篇论文的 overview</p><ol><li>第一篇</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">**Data description**</span><br><span class="line"></span><br><span class="line">The input datasets of the studies (Table 2) are classified as ‘paired’ or ‘unpaired’. ‘Paired’ means the same cells or the same type of cells are selected from different integrating modalities and used as anchors for the integration task. ‘Unpaired’ means the cells are not matched between different modalities, and no anchor is defined.</span><br><span class="line"></span><br><span class="line">MDL integration methods can be classified into three types, horizontal, vertical and diagonal data integration, depending on pairing and anchor information [136]. Horizontal integration uses shared features like genes to link data from different modalities, while vertical integration uses paired cells as anchors. In contrast, diagonal integration methods perform integration without using paired cells or shared features as anchors. These methods aim to build a simplified representation of the relationships between data modalities, assuming an underlying low-dimensional structure links them. The current review excludes studies in the horizontal category because they often use only one data modality from different sources. As shown in Table 2, only a few papers have used unpaired cells of different modalities to perform diagonal integration. SCIM, crossmodal-AE, STACI, GLUE, scJoint, sciCAN, scDART and Portal are examples of diagonal integration methods. Crossmodal-AE, scJoint and Portal perform both vertical and diagonal integration on paired or unpaired cell types.</span><br><span class="line"></span><br><span class="line">Table 2 also describes the datasets based on data sources, technology or platform used for sequencing the data and comparing modalities. Most studies performed the integration task between scRNA-seq and scATAC-seq [68, 76, 77, 83, 85, 91, 95, 100, 101, 105, 107, 119, 123, 130, 131]. Some studies performed integration of multiple modality pairs like scMM [76], Cobolt [77], SMILE [95], Portal [123], scMoGNN and scMDC [133]. For example, besides integrating scRNA-seq and scATAC-seq data, scMM and totalVI also integrated scRNA-seq and surface protein profiling data. Crossmodal-AE is the only study that performed integration between chromatin image and scRNA-seq data. STACI [135] integrated single-cell spatial transcriptomics data with chromatin images. Some studies go beyond modality pairs and can integrate multiple data modalities. For example, GLUE integrated three different omics data modalities and named it triple omics integration. SMILE also integrated three modalities using a combination of the two model variants.</span><br><span class="line"></span><br><span class="line">**Model architecture classification**</span><br><span class="line"></span><br><span class="line">Table 3 summarizes the recent MDL models developed for single-cell multi-omics data integration. All the models used two-dimensional numerical matrices to represent the input data. We categorize these models into seven groups, VAE, AE, encoders, GAN, FCNN, GNN and heterogenous models, detailed as follows.</span><br><span class="line"></span><br><span class="line">#### 4.2.1 VAE-based models</span><br><span class="line"></span><br><span class="line">SCIM adopts VAE to integrate scRNA-seq and CyTOF modalities. Each modality is modeled by an encoder-decoder network, and a discriminator is incorporated to identify a specific source modality from the latent representation of other modalities. Through adversarial training, SCIM can generate an integrated latent space. However, SCIM cannot predict one modality from another and thus cannot accomplish cross-modal translation tasks.</span><br><span class="line"></span><br><span class="line">scMM, similar to SCIM, aims to integrate multiple modalities into a shared space. However, scMM has the additional capability of cross-modal translation. scMM uses a VAE to integrate two modalities. The encoder-decoder network first takes the feature vectors for each modality as input. An encoder is trained to generate a low-dimensional joint variational posterior that can be factorized by a ‘mixture of experts model’ (MOE) [137]. This joint representation is then used to train decoders that reconstruct the underlying data distribution in each modality. The MOE factorization enables the separation of each modality from the joint representations, which helps scMM to perform cross-modality predictions.</span><br><span class="line"></span><br><span class="line">Cobolt adopts an approach similar to scMM in projecting different modalities into a shared latent space. However, Cobolt distinguishes itself from scMM in its attempt to integrate joint-modality data with single-modality data. Given the current prevalence of single-modality data over joint-modality data in both quality and quantity [77], there is a strong interest in integrating both types of multi-omics data. Cobolt employs three encoders to learn the latent feature distributions of the input modalities: one for scRNA-seq, one for joint-modality data (scRNA-seq + scATAC-seq) and another for scATAC-seq. Each encoder learns separate latent embeddings and posterior distributions of latent variables. Cobolt then projects the modalities into a shared latent space by taking the posterior mean of these distributions. Finally, three separate decoders learn from the shared latent embeddings.</span><br><span class="line"></span><br><span class="line">The MDL models described earlier can generate a shared feature representation (joint embedding) that preserves modality-specific information [105]. However, when significant noise or sparsity exists in joint-modality data, the resulting joint embedding may not accurately capture the biological variation, causing difficulties in downstream analysis and interpretation [105]. To address this issue, scMVAE and scMVP were developed. scMVAE utilizes one multimodal encoder, two single-modal encoders and two single-modal decoders. The multimodal encoder models scRNA-seq and scATAC-seq data with three joint-learning techniques. One is to estimate a joint posterior from the product of posteriors of each modality. One is to learn a joint-learning space using a neural network, and another is to obtain a concatenation of the original features of each modality. Meanwhile, the single-modal encoders play the roles of data normalization, denoising and imputation of the input modalities. scMVP has the same architecture as scMVAE, but scMVP’s joint-modality encoder only uses a neural network to learn the joint-learning space of the scRNA-seq and scATAC-seq modalities. scMVP improves joint embedding by connecting its two decoders through a cell-type-guided attention module that captures the correlation between the two modalities. Furthermore, scMVP’s single-modal encoders are connected to the joint embedding with two extra modules that ensure clustering consistency.</span><br><span class="line"></span><br><span class="line">The assumption that all data sources are equally valuable and follow the same distribution is not always true. For example, in scATAC-seq experiments, the amount of data per cell is typically lower and more variable than in scRNA-Seq experiments from the same cell [100]. Directly combining data using neural networks from such imbalanced modalities can lead to overfitting [100]. SAILERX was introduced to address these challenges by only learning scATAC-seq data with a VAE, and for scRNA-seq, using pre-trained scRNA-seq embeddings. SAILERX also enforces similarity between the latent space of both modalities through regularization, which preserves local cell structure across modalities. The goal is to avoid overfitting and allow hybrid integration of joint profiling data with single-modality data, similar to Cobolt.</span><br><span class="line"></span><br><span class="line">Combining RNA and protein data to create a unified representation of cell state is challenging due to technical biases and inherent noise in each data modality. In particular, protein data presents a unique challenge due to background noise from ambient or nonspecifically bound antibodies [87]. The VAE-based totalVI model provides a solution for integrating scRNA-seq and protein data while correcting for protein background noise. To achieve this, totalVI takes matrices of scRNA-seq and protein count data as input, along with categorical covariates such as experimental batch or donor information. The encoder then generates a joint latent representation of both modalities, which helps to control modality-specific noise properties and batch effects. Finally, the decoder estimates the parameters of the underlying distributions of both modalities from the joint latent representation while correcting for protein background noise.</span><br><span class="line"></span><br><span class="line">Integrating unpaired multi-omics data can be difficult since each modality has unique feature spaces. To address this issue, GLUE was developed to integrate unpaired multi-omics data via graph-guided embeddings. GLUE uses a separate VAE to model each data modality. To merge modality-specific feature spaces, GLUE constructed a knowledge-based graph using cross-modality regulatory interactions, with vertices representing the features of different omics data modalities and edges representing regulatory interactions. A variational graph AE (VGAE) is adopted to create graph embeddings from the knowledge-based graph. The VGAE is then connected with the modality-specific decoders to help integrate these unpaired multi-omics data.</span><br><span class="line"></span><br><span class="line">The above-discussed MDL techniques were not designed specifically for online integration tasks [131]. As a solution, SCALEX was developed to continuously integrate new single-cell multi-omics data without recalculating all previous integrations [131]. The VAE-based SCALEX model aims to create a generalized encoder for data projection without retraining, and it achieves this through three key design elements.</span><br><span class="line"></span><br><span class="line">#### 4.2.2 AE-based models</span><br><span class="line"></span><br><span class="line">Several studies have adopted AEs for multimodal data integration. One such approach is the k-coupled AE, which uses a multi-agent AE approach [71], where each AE agent learns a modality separately. These agent AEs are coupled by an overall cost function that measures the dissimilarity among the representations learned by the agent AEs. All agent AEs minimize this overall cost function during training to produce a better integrated latent representation. The k-coupled AE is useful for cross-modal translation. Another study, BABEL, uses two AE-based architecture to generate cross-modal translation. Two separate encoders learn two modalities separately and project them into a shared latent space, which is learned by two decoders to create the original modalities. Another AE-based model, scMDC, focuses on accurately clustering single-cell data. It uses a multimodal AE to learn a joint latent representation from the concatenated modalities of scRNA-seq and (CITE-seq or scATAC-sesq). Unlike the previous studies focusing on sequencing data only, crossmodal-AE integrates image and sequencing data. The approach of the crossmodal-AE is similar to BABEL. However, the AEs are customized according to specific modalities in crossmodal-AE. For example, to project single-cell image data, scRNA-seq, scATAC-seq and single-cell Hi-C data into the shared latent space, AEs corresponding to CNN, FCNN and GNN are designed, respectively. STACI extended the work of crossmodal-AE, which used AE with over-parameterization. Over-parameterization means extending the size of hidden layers to be greater than the input feature space. The model used separate decoders to obtain each modality from the latent embedding.</span><br><span class="line"></span><br><span class="line">#### 4.2.3 Encoder-based models</span><br><span class="line"></span><br><span class="line">The encoder-based SMILE model integrates single-cell multi-omics data using contrastive learning. There are two variants of SMILE: pSMILE and mpSMILE. The former has two encoders corresponding to two input modalities. One-layer multilayer perceptrons (MLPs) are applied to each encoder to reduce the dimensionality of its output. The outputs are then subjected to noise contrastive estimation to maximize mutual information in the shared latent space. mpSMILE uses two encoders as well but has one encoder duplicated to give more weight to the corresponding data modality. Doing so can improve discriminative representations [107, 138]. In another study, scJoint presents an encoder-based transfer learning method that learns a joint embedding space from scRNA-seq and scATAC-seq data. Since unpaired multi-omics data integration is challenging due to distinct feature spaces, scJoint uses two loss functions to identify orthogonal latent features and maximize the alignment of different modalities. In addition to a cross-entropy loss for cell-type prediction, the joint embedding space can be used by a k-nearest neighbor approach to transfer cell labels from scRNA-seq cells to ATAC-seq cells, further improving the joint embedding space.</span><br><span class="line"></span><br><span class="line">#### 4.2.4 GAN-based models</span><br><span class="line"></span><br><span class="line">MAGAN is a model that addresses the challenge of integrating unpaired data using a manifold alignment strategy. MAGAN uses a dual GAN framework consisting of two GANs, which align manifolds from two modalities. One GAN is responsible for creating a mapping from the first modality to the second modality, while the other GAN learns the mapping from the second to the first modality.</span><br><span class="line"></span><br><span class="line">**FCNN**: Existing methods for integrating unpaired data into a single latent space primarily focus on cells that form clusters rather than continuous cells that follow trajectories [8, 9, 139]. scDART addresses this limitation by utilizing a FCNN to project data into a shared latent space while preserving cell trajectories. The scDART model consists of two parts: the gene activity function, which generates a ‘pseudo-scRNA-seq’ count matrix from scATAC-seq data; and the projection module, which takes both the original scRNA-seq data and the ‘pseudo-scRNA-seq’ data as input to produce a shared latent space. The diffusion/random-walk-based distances between cells along the trajectory manifold in the original and the latent space are considered in the overall loss function to preserve the cell trajectory structure.</span><br><span class="line"></span><br><span class="line">**Graph neural network (GNN)**: Integration studies like BABEL, scMM and Cobolt often treat each cell as an independent input, which can overlook important high-order interactions between cells and modalities. Such interactions are critical for effective learning from single-cell data’s high-dimensional and sparse cell features. scMoGNN leverages GNNs to integrate single-cell modalities while preserving high-order structural information to address this limitation. Specifically, scMoGNN first constructs a cell-feature graph from a given modality and applies a graph CNN (GCNN) to obtain latent embeddings of cells. These cell embeddings are then fed into a task-specific head for downstream tasks such as modality prediction, matching and joint embedding.</span><br><span class="line"></span><br><span class="line">**Heterogenous model**: The SMILE model, mentioned earlier, requires cell anchors and can only be applied when corresponding cells are known across multiple modalities. sciCAN was developed to address this limitation. The sciCAN model consists of representation learning using an encoder and modality alignment using a GAN. The encoder employs noise contrastive estimation as its loss function to learn a joint low-dimensional representation. The GAN component includes two discriminators: one identifies source domains represented by a latent representation, and the other generates one data modality from the other, such as chromatin accessibility data from gene expression data. sciCAN differentiates itself from similar models like single-cell GAN (scGAN) [140] and AD-AE by using one additional cycle-consistent adversarial network, which introduces cycle-consistent loss to learn the connections between two modalities.</span><br><span class="line"></span><br><span class="line">With the emergence of Atlas-level scRNA-seq datasets, there is a growing need for integration techniques that can handle large numbers of cell populations and are computationally scalable. In response, the Portal model was developed. To align single-cell datasets, the Portal model employs a domain translation network of two encoders, generators and discriminators. The encoders learn latent embeddings for input modalities, the generators generate one modality data from the latent embedding of the other modality and the discriminators identify non-aligned data points to improve network training further.</span><br><span class="line"></span><br><span class="line">**Key tasks**</span><br><span class="line"></span><br><span class="line">Single-cell data integration can be divided into three key tasks: modality prediction, matching and joint embedding [98]. In the modality prediction task, one modality is predicted given the other modality. Among the surveyed papers, MAGAN and k-coupled AE both perform modality prediction tasks, as shown in Table 3. MAGAN predicts scRNA-seq from CyTOF or vice versa, while k-coupled AE predicts neuron morphological data from scRNA-seq. No studies have focused solely on modality matching. SCIM, Cobolt, scMVAE, SAILERX, GLUE, scMVP, Portal, MIRA and SCALEX all perform joint embedding tasks exclusively. In contrast, scMM performs joint embedding and modality prediction simultaneously. First, scRNA-seq and scATAC-seq modalities are jointly embedded, then used by decoders to predict one modality given another. Similarly, BABEL, scJoint, sciCAN, totalVI, crossmodal-AE, STACI and scDART perform both joint embedding and modality prediction tasks on various single-cell omics data modalities. SMILE performs joint embedding and modality matching tasks with scRNA-seq, scATAC-seq, DNA methylation and Hi-C modalities. scMoGNN performs all three tasks (joint embedding, modality prediction and modality matching) with mRNA, scATAC-seq and ADT modalities.</span><br><span class="line"></span><br><span class="line">**Fusion methods**</span><br><span class="line"></span><br><span class="line">Methods for integrating data from multiple modalities in an MDL model architecture are called fusion methods. Three types of fusion strategies have been identified: early fusion, intermediate fusion and late fusion [52] (as shown in Figure 2). The fusion strategies of the various studies are detailed as follows (Table 4).</span><br><span class="line"></span><br><span class="line">**Early fusion**: The strategy of ‘early fusion’ involves concatenating input features from different modalities to serve as the input of a deep learning model (Figure 3A). scMVAE, totalVI, STACI and SCALEX are among the studies that utilized the early fusion strategy. These studies aggregated modalities first and then utilized VAE to learn the joint latent embedding.</span><br><span class="line"></span><br><span class="line">**Intermediate fusion**: The majority of studies we surveyed have used intermediate fusion, where the modalities are learned first and fused later inside the MDL model. For instance, in Figure 3B, the marginal representation of modality 1 and 2 are learned first and integrated later inside the neural network layer. Intermediate fusion can be further classified into two categories: homogeneous and heterogeneous. Homogeneous fusion is used when the modalities are learned through the same type of neural network. In contrast, heterogeneous fusion is used when the modalities are learned through different types of neural networks. Moreover, based on representation, both homogeneous and heterogeneous fusion can be divided into marginal and joint types. The marginal representation uses features to represent latent components based on a single modality, while joint representation encodes information from several modalities.</span><br><span class="line"></span><br><span class="line">In joint homogeneous fusion, marginal representations are first concatenated, and then a joint representation is learned from that concatenated marginal representation. For example, SCIM assumes joint homogeneous fusion since modalities are learned by two separate VAEs and then imposed into a shared latent space. Joint heterogeneous intermediate fusion is a good strategy for learning informative cross-modality interactions, where different modalities are learned through different types of neural networks concatenated. Then, a joint representation is learned from that concatenated marginal representation using a separate neural network. For example, crossmodal-AE, SAILERX and sciCAN follow the joint heterogeneous fusion strategy.</span><br><span class="line"></span><br><span class="line">The marginal homogeneous fusion strategy involves using the same type of neural network to learn marginal feature representation from different modalities, which are later merged into the decision function. For example, SMILE adopted this strategy by using two separate encoders to learn two modalities and create two latent embeddings, followed by two MLPs that learned from both embeddings to minimize the model’s loss.</span><br><span class="line"></span><br><span class="line">**Late fusion**: Late fusion integrates the decisions of separate models to make a final decision (Figure 3C). k-Coupled AE and MIRA are examples of models that use the late fusion strategy. In k-coupled AE, two modalities are learned through two separate coupled AE, and the latent representations are later aggregated. In MIRA, two modalities are learned through two separate VAEs, and the latent representations are combined later to make the final decision.</span><br><span class="line"></span><br><span class="line">**Downstream analysis**</span><br><span class="line"></span><br><span class="line">The integration of single-cell modalities using MDL provides great assistance for downstream analysis. Following integration, the MDL models are assessed through downstream analysis and utilized for such purposes. Commonly practiced downstream analysis includes cell type discovery, differential expression analysis (DE), cell trajectory inference, cell matching and cis-regulatory analysis, as detailed below (Table 3).</span><br><span class="line"></span><br><span class="line">**Cell type discovery**: The goal of cell type discovery is to identify the different types of cells present within a sample. Most tools performed cell type discovery to validate their results and illustrate their usage. For example, SCIM recovered T cells by integrating scRNA and CyTOF modalities. scJoint found 19 cell types common between scRNA-seq and scATAC-seq data. However, the detected cell types often vary across the studies. For instance, in the crossmodal-AE study, scRNA-seq data from human peripheral blood mononuclear cells (PBMCs) [93] was analyzed and clustered, revealing the presence of four types of T cells. In comparison, SAILERX clustered the PBMC 10k dataset [2] and identified 29 cell types. Similarly, scMM performed clustering on the same PBMC dataset [2] and identified 54 cell types. Cell type discovery accuracy is often validated by comparing the consistency of the detected cell types with the cell labels annotated in the original data. For example, scMM compared their discovered cell types with the cell-type annotation of PBMC dataset [2]. Some studies such as SCALEX validated cell type discovery by assessing through quantitative clustering metrics such as ARI (adjusted Rand index), NMI (normalized mutual information) and silhouette scores. Crossmodal-AE performed protein immunofluorescence staining to validate the discovered cell types. In this experiment, they selected two genes, CORO1A and RPL10A, that were predicted to be strongly upregulated in specific subpopulations of naive T cells with distinct patterns of chromatin density. They then analyzed immunofluorescence staining data of the two proteins along with the chromatin images. They demonstrated that the tool effectively aligns gene expression with the image features, allowing for the characterization of distinct subpopulations of naive T cells.</span><br><span class="line"></span><br><span class="line">**DE**: The process of DE involves identifying genes that are expressed differently across distinct cell types. This analysis provides insights into how gene expression changes in response to various biological conditions [141]. The reviewed studies utilized DE analysis on several single-cell multi-omics datasets to investigate alterations in gene expression. For example, in a study conducted by Cobolt, DE analysis showed distinct expression levels of Adarb2 and Sox6 genes in scRNA-seq and scATAC-seq clusters, which are known markers distinguishing between CGE and Pvalb clusters. The scDART, SCALEX, STACI and SMILE also performed DE on their data and made discoveries supported by the literature. Most studies validated their DE analysis results utilizing the existing evidence. For instance, scDART compared their DE analysis findings with existing evidence [51]. On the other hand, totalVI performed Welch’s t-test and Wilcoxon rank-sum test to validate their DE analysis findings [87].</span><br><span class="line"></span><br><span class="line">**Trajectory inference**: Trajectory inference aims to identify the progression of a cellular dynamic process and organize cells based on their movement through the process. scMVP, sciCAN, scDART and MIRA all performed trajectory inference. For example, scMVP conducted trajectory inference analysis on growing bulge cells of the SHARE-seq mouse skin dataset and identified two paths from αhigh CD34+ bulge to new bulge cells. sciCAN conducted co-trajectory analysis to investigate the hematopoietic hierarchy. The scDART algorithm was evaluated by trajectory inference analysis on a neonatal mouse brain cortex dataset. Moreover, MIRA investigated hair follicle maintenance and differentiation, revealed the hierarchy of different follicle lineages and recreated the true layout of the follicle. All studies validated the trajectory inference results by comparing with the existing evidence [3].</span><br><span class="line"></span><br><span class="line">**Cell matching**: Cell matching has been used as an assessment technique to evaluate the effectiveness of joint latent embedding. For example, SCIM employed this strategy to match cells between scRNA and CyTOF modalities in a melanoma tumor sample. Crossmodal-AE employed the cell-matching strategy on the human lung adenocarcinoma dataset [92] to match samples between RNA-seq and ATAC-seq modalities. In addition, scDART evaluated the cell matching capability using the mouse neonatal brain cortex dataset [51]. To evaluate cell matching accuracy, several metrics such as k-nearest neighbors’ accuracy, neighborhood overlapping score and cosine similarity score were utilized. For instance, scDART utilized neighborhood overlapping and cosine similarity scores to evaluate their cell matching accuracy and achieved the neighborhood overlapping scores of 0.6 and the cosine similarity scores of 0.712 in the mouse neonatal brain cortex dataset [51].</span><br><span class="line"></span><br><span class="line">**cis-Regulatory analysis**: cis-Regulatory analysis studies various cis-acting DNA sequences that modulate gene transcription. It includes identifying distal and proximal gene regulatory regions such as enhancers and promoters, transcription factor binding sites and their binding patterns called motifs in regulatory regions, as well as the grammars orchestrated by these binding elements and motifs. Several tools, including scMM, SAILERX, MIRA, GLUE and scMVP, have performed cis-regulatory analysis as a downstream analysis of multi-omics data integration. For example, scMM identified enriched regulatory motifs in genes and peaks associated with latent dimensions, while SAILERX determined the top motifs that were most enriched in individual cell types. MIRA used topic modeling of cell states and the regulatory-potential modeling of individual gene loci to identify enriched motifs, while GLUE identified distal gene regulatory regions based on the cosine similarity between feature embeddings. All studies evaluated cis-regulatory analysis findings by comparing their predictions with the existing evidence. For example, scMVP compared their cis-regulatory analysis findings with a previous study [51] and found a higher enrichment of H3K27ac and H3K4me1 in the translation start site (TSS) distal peaks and H3K4me3 in the TSS proximal regions.</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><ol start="2"><li>第二篇</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">3.1 Approaches for paired data</span><br><span class="line"></span><br><span class="line">The Cobolt model (Gong et al., 2021) learns shared representations between modalities and is based on a multimodal VAE, where an independent encoder network is used for each modality and the learned parameters of the posterior distributions are combined using a PoE approach. Additionally, Cobolt can jointly integrate single-modality datasets with multi-omics datasets, allowing one to draw on the many publicly available scRNA-seq or scATAC-seq datasets.</span><br><span class="line"></span><br><span class="line">Multigrate (Lotfollahi et al., 2022) is another model that employs a PoE to combine the posteriors of different modalities. Additional datasets can be integrated into the model by minimizing the maximum mean discrepancy (MMD) loss between joint representations of different datasets.</span><br><span class="line"></span><br><span class="line">Similar to Cobolt and Multigrate, scMM (Minoura et al., 2021) is a VAE-based method that trains an encoder network for each modality independently. However, instead of combining the parameters of the posterior distributions using a PoE, a MoE is used. By equally mixing information from both modalities through the MoE, the model avoids putting too much emphasis on one individual modality only (Minoura et al., 2021). In addition, scMM provides a method for model interpretability that uses latent traversals, where synthetic cells are generated by the learned decoder and one latent variable is modified continually, while the others remain fixed. The Spearman correlations calculated between each latent variable and the features of each modality then allow relevant features to be identified. Additionally, by using a Laplace prior, scMM learns disentangled representations, with correlations between latent variables being penalized, which allows for better interpretation of individual features (Treppner et al., 2022).</span><br><span class="line"></span><br><span class="line">Similarly, the MultiVI model presented by Ashuach et al. (2021) is also based on a MoE with αₘ = 1/M where M denotes the number of modalities, as the authors use individual encoders for each data modality and then average the resulting variational posteriors. However, a regularization term is added to the ELBO, which penalizes the distance between the learned latent representations such that a joint representation can be inferred (Ashuach et al., 2021).</span><br><span class="line"></span><br><span class="line">While the single-cell multi-view profiler (scMVP) (Li et al., 2022) is also based on a multimodal VAE architecture with modality-specific encoders and decoders and a joint latent space, it more explicitly accounts for the much higher sparsity of single-cell measurements from joint profiling protocols, with a throughput of only one-tenth to one-fifth of that of single-modality assays (Li et al., 2022). Specifically, the authors employ attention-based building blocks for both the encoder and decoder. Attention mechanisms have first been proposed in computer science in the context of machine translation (Bahdanau et al., 2014; Kim et al., 2017) and are based on the idea of using flexible weighting of an input observation, to have the model specifically ‘attend to’ the most important parts of the observation. In the context of omics data, attention scores are assigned to the observed features (e.g., genes, chromatin loci) of each cell, to enhance the effect and interplay of specific features. In contrast to fixed weights, the attention scores are learned during model training and can thus adapt to highlight the most informative features for learning, e.g., latent representations. Attention-based mechanisms have specifically been popularized by transformer models (Vaswani et al., 2017) due to their high performance on sparse datasets in the area of natural language processing or protein structure prediction. In scMVP, the authors build on that by using multi-head self-attention transformer modules to capture local, long-distance correlation in the encoder and decoder of the term frequency-inverse document frequency-transformed (Stuart et al., 2021) scATAC-seq data while using simple attention blocks in the RNA encoder and decoder. Given the latent embedding, the modality-specific decoders are weighted according to the posterior probabilities of cell-type or cluster identity. To encourage consistency of the shared latent space, the decoder-reconstructed values of each modality are again embedded into the latent space, and the KL-divergence between the joint latent embedding and the modality-specific re-embedding from the reconstructed data is minimized as an additional loss term. This corresponds to the idea of cyclical adversarial training as described in Section 2.4 and Figure 1E. More generally, this concept is based on a cycle GAN (Zhu et al., 2017) and is also present in, e.g., Xu et al. (2021a); Zhao et al. (2022); Khan et al. (2022); Wang et al. (2022) and Zuo et al. (2021).</span><br><span class="line"></span><br><span class="line">SCALEX (Xiong et al., 2021) builds on SCALE (Single-Cell ATAC-seq Analysis via Latent feature Extraction) (Xiong et al., 2019), a tool for analyzing scATAC-seq data. The developers of SCALE found that its encoder could be beneficial in disentangling cell-type- and batch-related features, which would allow for online integration of different batches. Specifically, using a VAE, SCALEX integrates different batches into a batch-invariant embedding through simultaneous learning of a batch-free encoder and a batch-specific decoder. The latter contains a domain-specific batch normalization layer. This allows the encoder to concentrate only on batch-invariant biological data components while being oblivious to batch-specific variations. The resulting generalizability of the encoder further allows for the integration of new single-cell data in an online manner, i.e., without the need to retrain the model. The authors demonstrate this property of SCALEX by generating multiple expandable single-cell atlases.</span><br><span class="line"></span><br><span class="line">Another subgroup of models addresses the task of translating between different modalities. These cross-modality translation approaches, however, often do not learn a common latent representation of the data. For example, Polarbear (Zhang R. et al., 2022) trains VAEs on each of two modalities (here: scRNA-seq and scATAC-seq data) and then links the respective encoders to the decoders of the other modality. The authors intend that the training in the first stage, i.e., the training of the individual VAEs, takes place on publicly available single-assay data, whereby the translation task is carried out on SNARE-seq data in a supervised manner.</span><br><span class="line"></span><br><span class="line">Another such model called BABEL (Wu et al., 2021) similarly employs distinct modality-specific encoders and decoders for scRNA- and scATAC-seq data but utilizes a shared latent space. In contrast to PoE/MoE approaches, this joint representation is not constructed from separate spaces from each modality, but the encoders directly project onto the common latent space. Mutual cross-modal translation together with single-modality reconstruction are then used to train the model, i.e., from each modality-specific encoder, a sample of the joint latent representation is obtained and subsequently passed through both decoders to reconstruct both the scRNA and the scATAC profiles of the respective cell. Thus, both the reconstruction of the modality itself and the respective other modality based on the joint latent embedding are evaluated for each modality.</span><br><span class="line"></span><br><span class="line">Portal (Zhao et al., 2022) combines a domain translation framework with an adversarial training mechanism to integrate scRNA- and scATAC-seq data. Specifically, modality-specific encoders directly embed the data in a shared latent space and cross-modal generators are introduced to decode the latent representation to the respective other modality. The resulting domain translation networks for each modality are then trained to compete against adversarial discriminators on the domain of each modality that aims to distinguish between original cells from the respective modality and cells translated from the other modality. The discriminators are specifically designed to adaptively distinguish between domain-shared and domain-unique cells by thresholding the discriminator scores. Since, according to the authors, domain-unique cell populations are prone to be assigned with extreme discriminator scores, discriminators are, thus, made effectively inactive on cells with a high probability of being modality-specific, which avoids the risk of over-correction by enforced alignment of domain-unique cells. Further, additional regularizers are employed: an autoencoder loss based on the within-modality reconstructions, a latent alignment loss to encourage the consistency of a specific cell’s embedding and the embedding of its cross-modal reconstruction, and a cosine similarity loss between cells and their cross-modal reconstructions. Notably, Portal uses the first 30 principal components of a joint PCA as inputs for the model and employs a 20-dimensional latent space, such that the dimension reduction component is less pronounced than for the other models, and the data are not modeled as counts.</span><br><span class="line"></span><br><span class="line">The authors of Zuo and Chen (2021) have extended scMVAE and proposed Deep Cross-Omics Cycle Attention (DCCA) (Zuo et al., 2021), which improves some of the weaknesses of scMVAE. DCCA combines VAEs with attention transfer. While scMVAE combines two modalities into a shared embedding, which potentially attenuates modality-specific patterns, in the case of DCCA, each data modality is processed by a separate VAE. These VAEs can then learn from each other through mutual supervision based on semantic similarity between the embeddings of each omics modality.</span><br><span class="line"></span><br><span class="line">In the sciCAN model presented by Xu et al. (2021a), modality-specific autoencoders map the input data to a latent space for each modality, and a discriminator is employed to distinguish between the two modalities based on their latent representations. Additionally, a cross-modal generator is employed that generates synthetic scATAC-seq data based on the scRNA-seq latent representation, and a second discriminator is employed to distinguish between generated and real scATAC-seq samples. Additionally, the generated scATAC-seq data can be fed to the encoder again, and the latent representation is compared with the original latent representation from the scRNA-seq data used for generating the scATAC-seq data, thus introducing a cycle consistency loss (see Figure 1E, Section 2.4). Notably, the model does not necessarily expect paired measurements from the same cell but employs a shared encoder for both modalities, and, thus, requires a common feature set.</span><br><span class="line"></span><br><span class="line">The authors of Hu et al. (2022) propose the DAVAE model based on domain-adversarial and variational approximation to integrate multiple single-cell datasets and paired scRNA-seq and scATAC-seq data. The model employs an adversarial training strategy to remove batch effects and enable transfer learning between modalities, by incorporating a domain classifier that tries to determine the batch or modality label based on the latent representation of VAE and training the VAE encoder to ‘fool’ the classifier via an adversarial loss component. Similarly to Portal and sciCAN, the DAVAE model also employs a shared encoder and thus requires a common set of input features.</span><br><span class="line"></span><br><span class="line">Similarly, the scDEC model proposed by Liu et al. (2021) is based on a pair of generative adversarial models to learn a latent representation. While focusing on scATAC-seq data analysis, this approach also allows for integrative analysis of multi-modal scATAC and scRNA-seq datasets for trajectory inference during differentiation processes and cell type identification based on the joint latent representation.</span><br><span class="line"></span><br><span class="line">Finally, MIRA (Lynch et al., 2022) combines probabilistic cell-level topic modeling (Blei, 2012) with gene-level regulatory potential (RP) modeling (Wang et al., 2013; Qin et al., 2020) to determine key regulators responsible for fate decisions at lineage branch points. The topic model uses a VAE with a Dirichlet prior to learn both the topic of the gene transcription and the topic of gene accessibility for each cell to derive the cell’s identity. Complementing MIRA’s topic model, its RP model integrates the transcription and accessibility information for each gene locus to infer how the expression of the respective gene is influenced by surrounding regulators. To this end, the topic model learns the rate with which the regulatory influence of enhancers decays with increasing genomic distance. In addition, the identity of key regulators is identified by analyzing transcription factor motif enrichment or occupancy.</span><br><span class="line"></span><br><span class="line">3.2 Approaches for unpaired data</span><br><span class="line"></span><br><span class="line">Since the generation of multi-omics measurements in the same cell is still costly and experimentally complex, many methods for integrating datasets measured in different cells are being developed.</span><br><span class="line"></span><br><span class="line">Because of the difficulty of linking latent representations learned from variational autoencoders in the absence of measurement pairing information, Lin et al. (2022) proposed a transfer learning approach. Although not a DGM, it is worth mentioning in this article because of its usefulness and the possibility of adapting it to unsupervised settings. Notably, it represents a method for a horizontal alignment task, i.e., it relies on a common set of features as anchors and thus requires the translation of scATAC peaks to gene activity scores.</span><br><span class="line"></span><br><span class="line">In a similar spirit, the scDART model proposed by Zhang Z. et al. (2022) learns a neural network-based joint embedding of unpaired scRNA-seq and scATAC-seq data by composing the embedding network with a gene-activity module network that maps scATAC peaks to genes. In addition, scDART can leverage partial cell matching information by using it as a prior to inform the training of the gene activity function.</span><br><span class="line"></span><br><span class="line">Similar to the sciCAN model presented by Xu et al. (2021a), scAEGAN (Khan et al., 2022) also embraces the concept of cycle consistency, integrating the adversarial training mechanism of a cycle GAN (Zhu et al., 2017) into an autoencoder framework. Specifically, for each modality, a discriminator and a generator are defined. In addition to the standard GAN loss for each modality, a cycle loss is calculated by mapping a cell from one modality to the second modality with the second modality’s generator and mapping it back to the first modality with the first modality’s generator and comparing that to the original observation. Unlike for Xu et al. (2021a), the model does not rely on a common feature set but first trains an autoencoder model independently for each modality before training a cycle GAN on the two latent spaces to enforce their consistency.</span><br><span class="line"></span><br><span class="line">A similar approach is employed in the Contrastive Cycle Autoencoder (Con-AAE) proposed by Wang et al. (2022). Again, the consistency between latent spaces of modality-specific autoencoders is enforced by a cycle consistency loss. However, here, it is more tightly integrated within the AE architecture, as the modality-specific encoder and decoders are used as generators, i.e., samples from one modality are embedded with the modality-specific encoder but decoded with the decoder of the other modality, and subsequently encoded with the other modality encoder back to the latent space, where they are compared with the original latent representation from the original encoder of the modality.</span><br><span class="line"></span><br><span class="line">A purely GAN-based approach to integrating unpaired data by aligning the respective manifolds is presented in Amodio and Krishnaswamy (2018).</span><br><span class="line"></span><br><span class="line">Another line of research for the integration of unpaired multi-omics data focuses on the concept of optimal transport (Peyré and Cuturi, 2019). A separate embedding or distance matrix is constructed from each modality, and the alignment task is formulated to find an optimal coupling between the two embeddings or distance matrices. An optimal coupling corresponds to finding a map along which one modality can be “transported” with minimal cost to the other, which can be formalized as an optimal transport problem (Peyré and Cuturi, 2019). Examples for such optimal transport-based methods are UnionCom (Cao et al., 2020), SCOT (Demetci et al., 2022) and Pamona (Cao et al., 2021). While these approaches typically rely on computing a coupling between modality-specific distance matrices and are not deep learning-based, a recent approach called uniPort employs a VAE architecture and solves an optimal transport problem in the latent space. More specifically, a shared encoder that requires a common input feature set across modalities is used to project the data into a common latent space, is combined with modality-specific decoders for reconstruction, and an optimal transport loss is minimized between the latent cell embeddings from different modalities.</span><br><span class="line"></span><br><span class="line">Finally, the recently published Graph-Linked Unified Embedding (GLUE) framework (Cao and Gao, 2022) is based on the construction of a guidance graph based on prior knowledge of the relations between features of the different modalities to explicitly model regulatory interactions across different modalities with distinct feature spaces. This is achieved by learning joint feature embeddings from the knowledge graph with a graph VAE and linking them to modality-specific autoencoders. Specifically, the decoder of these modality-specific AEs is given by the inner product of the feature embeddings and the cell embeddings from the latent space of the respective modality. Additionally, the cell embeddings of different modalities are aligned using an adversarial discriminator.</span><br></pre></td></tr></table></figure><ol start="4"><li>第四篇</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br></pre></td><td class="code"><pre><span class="line">### 4.1 Single-Cell RNA-seq Data Pre-processing and Quality Control</span><br><span class="line"></span><br><span class="line">#### 4.1.1 Pre-processing and Quality Control</span><br><span class="line"></span><br><span class="line">Cell barcodes are essential for distinguishing various cell populations within a sequenced sample. However, inaccuracies such as doublets (multiple cells tagged by a single barcode) and empty droplets/wells (no cells tagged) necessitate a quality control (QC) step in scRNA-seq analysis. Several pre-processing pipelines, including Cell Ranger [94], inDrops [95], SEQC [96], and zUMIs [97], incorporate QC measures. The dimensionality of the resulting count matrix depends on the number of barcodes and transcripts. While noise rates vary across reads and count data, standard research pipelines typically employ uniform processing techniques [98].</span><br><span class="line"></span><br><span class="line">Despite the richness of scRNA-seq data, its complexity and higher noise levels compared to bulk RNA-seq pose significant challenges for raw data processing and downstream analysis. Unwanted variations, such as biases and artifacts, require extensive QC and normalization efforts [99]. Common QC metrics include the number of counts per barcode (count depth), the number of genes detected per barcode, and the fraction of counts from mitochondrial genes [100]. Additionally, experimental factors like sample damage during dissociation can result in low-quality scRNA-seq libraries, leading to erroneous downstream findings. There is a pressing need for more efficient and accurate methods to filter low-quality cells during library preparation. Deep Learning (DL) models, with their multitasking and scaling capabilities, hold promise for end-to-end analyses that perform QC, data correction, and downstream analyses simultaneously. Preliminary works, such as the scVI framework [40], have demonstrated the potential of DL models in developing comprehensive single-cell pipelines.</span><br><span class="line"></span><br><span class="line">Due to the limited number of studies focused specifically on pre-processing and QC, this review emphasizes DL applications related to normalization, data correction, and downstream analysis.</span><br><span class="line"></span><br><span class="line">#### 4.1.2 Normalization</span><br><span class="line"></span><br><span class="line">Normalization is a critical initial step in pre-processing scRNA-seq data, addressing issues like low input content and systematic measurement biases [101]. The goal is to detect and remove variations caused by technical artifacts or unintended biological effects, such as batch effects [102]. Traditional normalization methods designed for bulk RNA-seq and microarray data are often applied to scRNA-seq data but may overlook essential scRNA-seq-specific aspects [102].</span><br><span class="line"></span><br><span class="line">For scRNA-seq, normalization techniques can be categorized into:</span><br><span class="line"></span><br><span class="line">- **Scaling Techniques** [103]</span><br><span class="line">- **Regression-Based Techniques** for identified nuisance factors [101,104]</span><br><span class="line">- **Spike-In-Based Techniques** using External RNA Controls Consortium (ERCC) sequences [105,106]</span><br><span class="line"></span><br><span class="line">However, these methods are often tailored to specific experiments and may not generalize across different research designs and protocols. While some DL-based normalization methods have been proposed to generalize the normalization process, accounting for the technical noise inherent in scRNA-seq data remains an ongoing challenge and active research area [13].</span><br><span class="line"></span><br><span class="line">#### 4.1.3 Data Correction</span><br><span class="line"></span><br><span class="line">Normalization addresses noise and bias in scRNA-seq data, but normalized data can still exhibit unexpected variability due to technical and biological factors such as batch effects, dropouts, and cell cycle effects. Data correction aims to mitigate these additional sources of variability, which is essential for accurate downstream analyses [107]. It is recommended to address biological and technical covariates separately [107]. Designing DL models that can simultaneously handle these challenges is complex, and currently, no DL models are widely adopted for data correction in the field.</span><br><span class="line"></span><br><span class="line">##### 4.1.3.1 Dropout</span><br><span class="line"></span><br><span class="line">Dropout is a significant issue in scRNA-seq datasets, characterized by instances where a gene is expressed in one cell but not detected in another [108,109]. Dropout can result from low mRNA levels during library preparation or the stochastic nature of gene expression [110,111]. This leads to &quot;false&quot; zeros—missing values that do not reflect true gene inactivity [113]. Addressing dropouts is crucial as they introduce technical variability and noise, complicating analyses like clustering and trajectory inference [65].</span><br><span class="line"></span><br><span class="line">**Imputation Approaches:**</span><br><span class="line"></span><br><span class="line">- **Traditional Methods:** Such as MAGIC [115], SAVER [116], scImpute [117], DrImpute [108], and LSImpute [118], which may not account for the non-linearity and high sparsity of scRNA-seq data.</span><br><span class="line">- **Deep Learning-Based Methods:** Primarily based on Autoencoders (AEs) and Variational Autoencoders (VAEs), offering scalable solutions for large datasets.</span><br><span class="line"></span><br><span class="line">**Notable DL-Based Imputation Models:**</span><br><span class="line"></span><br><span class="line">- **AutoImpute [119]:** Uses overcomplete AEs to impute dropouts by learning the underlying distribution of scRNA-seq data.</span><br><span class="line">- **Deep Count AE (DCA) [26]:** Utilizes a negative binomial noise model to account for count distribution and overdispersion, scalable to millions of cells.</span><br><span class="line">- **TRANSLATE [27]:** A DL model based on AEs that assumes all zeros are missing values, effectively distinguishing between true and false zeros.</span><br><span class="line">- **SAUCIE [120]:** A regularized AE that denoises and imputes data, enhancing downstream analyses like differential gene expression.</span><br><span class="line">- **ScScope [121]:** A recurrent AE that iteratively imputes data using a recurrent network layer.</span><br><span class="line">- **DeepImpute [65] &amp; deepMC [66]:** Non-AE-based models that use sub-neural networks and deep matrix factorization, respectively.</span><br><span class="line">- **scVI [40]:** A hierarchical Bayesian model using a DNN to define conditional probabilities, accurately recovering gene expression signals.</span><br><span class="line"></span><br><span class="line">Recent evaluations suggest that methods like ENHANCE, MAGIC, SAVER, and SAVER-X offer the best overall results in terms of efficiency, accuracy, and robustness [122]. Additionally, **autoCell [74]**, introduced in 2023, employs a VAE network with graph embedding and a probabilistic depth Gaussian mixture model for comprehensive scRNA-seq data analysis.</span><br><span class="line"></span><br><span class="line">##### 4.1.3.2 Batch Effects Correction</span><br><span class="line"></span><br><span class="line">Batch effects arise from technical variations across different sequencing runs, platforms, or experimental conditions [123]. Removing batch effects is crucial for accurate downstream analyses but remains challenging due to the heterogeneity of scRNA-seq data [126,127].</span><br><span class="line"></span><br><span class="line">**Statistical Methods:**</span><br><span class="line"></span><br><span class="line">- **ComBat [125]:** A parametric empirical Bayes framework.</span><br><span class="line">- **Seurat’s Canonical Correlation Analysis (CCA) [128]:** A nonlinear method for batch correction.</span><br><span class="line">- **scBatch [123]:** A method tailored for scRNA-seq data.</span><br><span class="line">- **Differential Testing Frameworks:** Including limma [129], MAST [130], and DESeq2 [131], which incorporate batch effects as covariates.</span><br><span class="line"></span><br><span class="line">**Deep Learning-Based Batch Correction Models:**</span><br><span class="line"></span><br><span class="line">- **Haghverdi et al. [1]:** Developed a method using Mutual Nearest Neighbors (MNN) to align datasets into a shared space.</span><br><span class="line">- **Scanorama [132]:** Identifies and merges common cell types across datasets using MNN in reduced dimensions.</span><br><span class="line">- **BBKNN [133]:** A graph-based algorithm that removes batch effects by linking analogous cells across batches.</span><br><span class="line">- **Residual Neural Networks (ResNets) [134]:** Used for non-linear batch effect correction by reducing Maximum Mean Discrepancy (MMD) between distributions [135].</span><br><span class="line">- **Deep Embedding Algorithm for Single-Cell Clustering (DESC) [136]:** An unsupervised DL algorithm that removes batch effects while clustering.</span><br><span class="line">- **Batch Effect ReMoval Using Deep Autoencoders (BERMUDA) [138]:** An unsupervised framework that combines batches and amplifies biological signals.</span><br><span class="line">- **SCIM [218], GLUER [219], scPoli [220], BAVARIA [221], SciPENN [222], BABEL [86], DeepMAPS [219], scFAN [180], BERMUDA [138], and scDEC [187]:** Various DL models addressing batch effect correction with different strategies and capabilities.</span><br><span class="line"></span><br><span class="line">#### 4.1.3.3 Dimensionality Reduction</span><br><span class="line"></span><br><span class="line">Dimensionality reduction is essential for visualizing and analyzing scRNA-seq data, which typically involves thousands of genes [140]. Common techniques include PCA [141], t-SNE [142], diffusion maps [143], GPLVM [144,145], SIMLR, and UMAP [75]. While linear methods like PCA struggle with the complex structures in single-cell data, nonlinear techniques like t-SNE and UMAP effectively capture these complexities but have drawbacks such as sensitivity to parameters and computational cost [13].</span><br><span class="line"></span><br><span class="line">**Deep Learning-Based Dimensionality Reduction Models:**</span><br><span class="line"></span><br><span class="line">- **scVI [159]:** A VAE-based model that uses raw count data to learn latent representations without extensive pre-processing.</span><br><span class="line">- **scvis [146]:** A VAE-based model that offers better global structure preservation and interpretability compared to t-SNE but has longer runtimes.</span><br><span class="line">- **VASC [140]:** Combines VAEs with a zero-inflated layer to model dropout events, outperforming PCA, t-SNE, and ZIFA in capturing nonlinear patterns.</span><br><span class="line">- **BasisVAE [76]:** Incorporates a hierarchical Bayesian clustering prior within a VAE framework for joint dimensionality reduction and clustering.</span><br><span class="line">- **GOAE &amp; GONN [77]:** AE-based models that integrate Gene Ontology (GO) information to enhance clustering and dimensionality reduction.</span><br><span class="line">- **scDeepCluster [158]:** Combines DCA modeling with DESC clustering for scalable and efficient clustering, though it lacks pairwise distance considerations.</span><br><span class="line">- **G3DC [80]:** A deep embedded clustering method that uses graph loss based on gene networks and reconstruction loss for improved clustering.</span><br><span class="line">- **scDFC [161]:** An AE-based algorithm that integrates attributed feature clustering and structure-attention feature clustering for enhanced representation.</span><br><span class="line">- **DeepVelo [168]:** A DNN-based approach empowered by deep Graph Convolutional Networks (GCNs) for predicting RNA velocity without predefined kinetic patterns.</span><br><span class="line"></span><br><span class="line">Optimizing these algorithms for efficiency and scalability remains a critical area for future research, especially as single-cell datasets continue to grow in size and complexity.</span><br><span class="line"></span><br><span class="line">#### 4.1.3.4 In-Silico Generation and Augmentation</span><br><span class="line"></span><br><span class="line">In-silico data generation and augmentation address limitations in scRNA-seq data availability and sample sizes by providing fast, reliable, and cost-effective synthetic data. Traditional data augmentation techniques from areas like image and text classification are being replaced by DL-based generative models, primarily VAEs and GANs.</span><br><span class="line"></span><br><span class="line">**Generative Models for scRNA-seq Data:**</span><br><span class="line"></span><br><span class="line">- **scGAN [51]:** The first GAN-based method for scRNA-seq data generation and augmentation, utilizing Wasserstein-GAN to learn the underlying data manifold.</span><br><span class="line">- **ACTIVA [27]:** A VAE-based model with a single-stream adversarial VAE conditioned on cell-type information, offering faster training and comparable performance to scGAN.</span><br><span class="line">- **SIMPA [182]:** A DL-based imputation algorithm for single-cell ChIP-seq data that integrates sparse input with bulk ChIP-seq experiments.</span><br><span class="line">- **autoCell [74]:** A VAE-based method with graph embedding and a probabilistic depth Gaussian mixture model for comprehensive scRNA-seq data analysis.</span><br><span class="line"></span><br><span class="line">These generative models enhance scRNA-seq pipelines by enabling benchmarking of new algorithms, improving classifier accuracy, and identifying disease-specific gene networks. They facilitate the analysis of smaller datasets, potentially reducing the need for extensive patient or animal studies.</span><br><span class="line"></span><br><span class="line">#### 4.1.4 Downstream Analysis</span><br><span class="line"></span><br><span class="line">Post pre-processing, downstream analysis methods derive biological insights and identify underlying mechanisms. Key tasks include:</span><br><span class="line"></span><br><span class="line">##### 4.1.4.1 Clustering and Cell Annotation</span><br><span class="line"></span><br><span class="line">Clustering classifies cell subpopulations based on gene expression profiles, essential for creating cellular atlases like the Mouse Cell Atlas [152] and Human Cell Atlas [154]. DL-based clustering methods have emerged as powerful tools due to their ability to handle complex, high-dimensional data.</span><br><span class="line"></span><br><span class="line">**Notable DL-Based Clustering Models:**</span><br><span class="line"></span><br><span class="line">- **DESC [136]:** An AE-based method that clusters scRNA-seq data with a self-training target distribution, outperforming several existing methods.</span><br><span class="line">- **scAnCluster [157]:** Combines deep AEs with fuzzy k-means clustering and integrates cell marker information for enhanced annotation.</span><br><span class="line">- **scDeepCluster [158]:** Merges DCA modeling with DESC clustering for efficient, scalable clustering with high accuracy.</span><br><span class="line">- **GOAE &amp; GONN [77]:** Utilize Gene Ontology information within AE frameworks to improve clustering and interpretability.</span><br><span class="line">- **scVAE [159]:** A VAE-based model that predicts gene expression and provides flexible latent representations for clustering.</span><br><span class="line">- **scDCCA [160]:** Combines denoising AEs with dual contrastive learning for robust feature extraction and clustering.</span><br><span class="line">- **G3DC [80]:** Incorporates graph-based loss functions to ensure discriminative and informative embeddings.</span><br><span class="line">- **scDFC [161]:** Integrates attributed feature clustering and structure-attention modules within an AE framework.</span><br><span class="line">- **scPoli [220], BAVARIA [221], SciPENN [222], BABEL [86], DeepMAPS [219], and scFAN [180]:** Various DL models addressing clustering with additional functionalities like batch effect removal and cell-type annotation.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Unknown Number of Clusters:** Determining the optimal number of clusters remains a significant challenge.</span><br><span class="line">- **Scalability:** As scRNA-seq datasets grow, maintaining computational efficiency is crucial.</span><br><span class="line">- **Noise and Doublets:** High noise levels and the presence of doublets can lead to erroneous clustering results.</span><br><span class="line"></span><br><span class="line">##### 4.1.4.2 Cell-Cell Communication Analysis</span><br><span class="line"></span><br><span class="line">Understanding intercellular communication is vital for elucidating biological processes. scRNA-seq data allows the inference of cell-cell interactions based on ligand-receptor expression patterns.</span><br><span class="line"></span><br><span class="line">**DL-Based Cell-Cell Communication Models:**</span><br><span class="line"></span><br><span class="line">- **DeepCCI [164]:** Utilizes Graph Convolutional Networks (GCNs) to incorporate topological properties and gene expression for predicting intercellular communications.</span><br><span class="line">- **GCNG [165]:** Encodes spatial data as graphs and integrates it with expression levels using supervised training for enhanced spatial transcriptomics analysis.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Lack of Ground Truth:** Evaluating the accuracy of predicted interactions is difficult due to the absence of comprehensive ground truth data.</span><br><span class="line">- **Computational Complexity:** Modeling interactions across millions of cells requires efficient computational strategies.</span><br><span class="line"></span><br><span class="line">##### 4.1.4.3 RNA Velocity</span><br><span class="line"></span><br><span class="line">RNA velocity provides insights into the dynamic changes in gene expression, predicting the future state of individual cells based on spliced and unspliced mRNA ratios.</span><br><span class="line"></span><br><span class="line">**DL-Based RNA Velocity Models:**</span><br><span class="line"></span><br><span class="line">- **DeepVelo [168]:** A DNN-based approach that leverages deep GCNs to predict RNA velocities without predefined kinetic patterns, enhancing the analysis of complex cellular dynamics.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Normalization:** Accurately accounting for factors like cell size and splicing efficiency is critical for precise velocity estimations.</span><br><span class="line">- **Model Integration:** Integrating RNA velocity with other data modalities and downstream analyses remains an area for future research.</span><br><span class="line"></span><br><span class="line">### 4.2 Deep Learning in Single-Cell Genomics</span><br><span class="line"></span><br><span class="line">Traditional sequencing methods average signals across cell populations, masking cellular heterogeneity. Single-cell genomics, particularly scRNA-seq, enables the investigation of individual cell states and interactions, transforming biological research. Recent advancements allow for multimodal omics measurements, integrating transcriptomic and epigenomic data within the same experiment.</span><br><span class="line"></span><br><span class="line">**Applications of DL in Single-Cell Genomics:**</span><br><span class="line"></span><br><span class="line">- **Cell-Type Identification:** Utilizing AEs and CNNs to classify and annotate cell types based on gene expression and protein markers.</span><br><span class="line">- **DNA Methylation Analysis:** Predicting methylation regions using CNN-based models like DeepCpG [171].</span><br><span class="line">- **Histone Modification Analysis:** Imputing and analyzing histone mark data with models like SIMPA [182].</span><br><span class="line">- **CNV and SNP Prediction:** Detecting copy number variations and single nucleotide polymorphisms using AE-based models like dudeML [185], DeepCNV [186], and scDEC [187].</span><br><span class="line">- **Transcription Factor (TF)-Gene Relationship Prediction:** Inferring regulatory relationships using CNNs and DL frameworks like CNNC [179] and scFAN [180].</span><br><span class="line"></span><br><span class="line">**Notable DL Models in Single-Cell Genomics:**</span><br><span class="line"></span><br><span class="line">- **DeepCpG [171]:** A CNN-based method for predicting DNA methylation states from scRNA-seq data.</span><br><span class="line">- **SIMPA [182]:** Integrates single-cell ChIP-seq data with bulk ChIP-seq experiments using DL for imputation.</span><br><span class="line">- **scVI [40]:** A VAE-based model for comprehensive single-cell analysis, including imputation and normalization.</span><br><span class="line">- **DESC [136], scAnCluster [157], scDeepCluster [158], GOAE &amp; GONN [77], and scDFC [161]:** Various AE and VAE-based models for clustering, normalization, and downstream analyses.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Data Sparsity and Noise:** Single-cell data is inherently noisy and sparse, requiring robust DL models for accurate analysis.</span><br><span class="line">- **Scalability:** Handling large datasets with millions of cells necessitates efficient and scalable DL architectures.</span><br><span class="line">- **Integration Across Modalities:** Combining diverse omics data types within a unified framework remains complex.</span><br><span class="line"></span><br><span class="line">### 4.3 Deep Learning in Spatial Transcriptomics</span><br><span class="line"></span><br><span class="line">Spatial Transcriptomics (ST) combines gene expression profiling with spatial information, allowing researchers to understand cellular interactions within their native tissue context. Unlike scRNA-seq, which dissociates cells, ST retains spatial coordinates, offering insights into tissue organization and cellular interactions.</span><br><span class="line"></span><br><span class="line">**Challenges in ST:**</span><br><span class="line"></span><br><span class="line">- **Resolution Limitations:** Array-based ST methods capture gene expression from multiple cells within each spot, complicating the assignment of expression profiles to individual cells.</span><br><span class="line">- **Data Integration:** Combining spatial data with scRNA-seq requires sophisticated computational models to deconvolute mixed signals.</span><br><span class="line"></span><br><span class="line">**Deep Learning-Based ST Models:**</span><br><span class="line"></span><br><span class="line">- **DeepST [195]:** Recognizes spatial domains in human dorsolateral prefrontal cortex datasets, outperforming existing methods in accuracy and scalability.</span><br><span class="line">- **DEEPsc [196]:** Imputes spatial information onto scRNA-seq datasets using reference atlases, offering improved accuracy and robustness.</span><br><span class="line">- **Tangram [197]:** Aligns scRNA-seq profiles with spatial data, enabling precise mapping of gene expression to tissue locations.</span><br><span class="line">- **SpaCell [198]:** Integrates gene expression data with imaging data using a DL framework for enhanced spatial analysis.</span><br><span class="line">- **SEDR [199]:** Uses AEs and graph-based models to co-embed gene expression with spatial data, improving clustering and trajectory analyses.</span><br><span class="line">- **DeLTA 2.0 [200]:** Employs Deep CNNs for analyzing time-lapse images of individual cells, enabling precise gene expression and cell growth measurements.</span><br><span class="line"></span><br><span class="line">**Emerging Models:**</span><br><span class="line"></span><br><span class="line">- **DeepMAPS [219]:** A transformer-based model with graph attention mechanisms for integrating multi-omics spatial data.</span><br><span class="line">- **Manifold-Aligning GAN (MAGAN) [214]:** Aligns manifolds from different data domains using GANs for integrated single-cell data analysis.</span><br><span class="line">- **ExpiMap [89]:** Utilizes conditional VAEs for enhanced atlas integration, capturing biologically significant gene programs with interpretability.</span><br><span class="line"></span><br><span class="line">**Future Directions:**</span><br><span class="line"></span><br><span class="line">As ST technologies evolve, DL models are expected to become integral for integrating spatial and single-cell data, enabling comprehensive tissue mapping and understanding of cellular ecosystems. The development of models that can efficiently handle the high dimensionality and complexity of ST data will be crucial for advancing spatial biology research.</span><br><span class="line"></span><br><span class="line">### 4.4 Integrating scRNA-seq and Spatial Transcriptomics (Spot Deconvolution)</span><br><span class="line"></span><br><span class="line">Integrating scRNA-seq with ST data is essential for mapping individual cell gene expression profiles to their spatial locations within tissues. This integration addresses the limitation of ST methods that capture mixed gene expression from multiple cells per spot.</span><br><span class="line"></span><br><span class="line">**Key Models for Spot Deconvolution:**</span><br><span class="line"></span><br><span class="line">- **SPOTlight [201]:** Utilizes seeded Non-Negative Matrix Factorization (NMF) regression to deconvolute ST spots using single-cell transcriptomes. It relies on cell-type-specific gene profiles and unique marker genes for initialization. However, SPOTlight lacks flexibility in integrating datasets from different batches or sequencing technologies and does not account for various sources of biological and technical variability.</span><br><span class="line">  </span><br><span class="line">- **Stereoscope [203]:** A statistical framework that models gene expression counts as a negative binomial distribution, leveraging cell-type-specific profiles to infer the contribution of each cell type to each ST spot.</span><br><span class="line"></span><br><span class="line">- **cell2location [204]:** Builds upon Stereoscope by incorporating a Bayesian framework that controls for technical variability, allowing integration across different technologies with shared and modality-specific parameters.</span><br><span class="line"></span><br><span class="line">- **DestVI [205]:** Employs variational inference for multi-resolution analysis, providing high-resolution spatial characterizations and precise cell-type abundance estimates within spots.</span><br><span class="line"></span><br><span class="line">- **Tangram [197], SpaCell [198], DeepMAPS [219], scPoli [220], BAVARIA [221], SciPENN [222], BABEL [86], and scFAN [180]:** Various DL models that enhance the integration of scRNA-seq and ST data through advanced architectures like GANs, VAEs, and transformer-based models.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Batch Effects and Technical Variability:** Integrating data from different sources and technologies requires models that can account for batch effects and maintain biological heterogeneity.</span><br><span class="line">  </span><br><span class="line">- **Scalability:** Handling large-scale datasets with millions of cells and spatial spots demands efficient computational frameworks.</span><br><span class="line">  </span><br><span class="line">- **Accuracy in Deconvolution:** Precisely assigning cell types to spatial spots, especially in regions with rare or similar cell types, remains challenging.</span><br><span class="line"></span><br><span class="line">**Future Directions:**</span><br><span class="line"></span><br><span class="line">Developing DL models that can robustly integrate scRNA-seq and ST data while accounting for technical and biological variability will enhance the resolution and accuracy of tissue mapping. Advances in model architectures and training strategies are expected to facilitate more precise and scalable deconvolution methods.</span><br><span class="line"></span><br><span class="line">### 4.5 Deep Learning in the Integration of Single-Cell Multimodal Omics Data</span><br><span class="line"></span><br><span class="line">Single-cell multimodal omics integrates diverse data types (e.g., transcriptomic, epigenomic, proteomic) from the same cell or experiment, providing a comprehensive view of cellular states and regulatory mechanisms. Deep Learning (DL) models are particularly well-suited for this integration due to their ability to handle high-dimensional, heterogeneous data and learn complex, non-linear relationships.</span><br><span class="line"></span><br><span class="line">**Key DL-Based Integration Models:**</span><br><span class="line"></span><br><span class="line">- **scMVAE [211]:** A multimodal VAE that profiles both transcriptomic and chromatin accessibility information within the same cells, learning a non-linear joint embedding for various downstream tasks.</span><br><span class="line"></span><br><span class="line">- **MAGAN [214]:** A GAN-based model that aligns manifolds from different data domains (e.g., CyTOF and scRNA-seq) under the assumption of complementary information between measurements.</span><br><span class="line"></span><br><span class="line">- **UnionCom [216]:** Utilizes optimal transport principles within a VAE framework to align latent embeddings across modalities, though scalability to millions of cells remains a limitation.</span><br><span class="line"></span><br><span class="line">- **SMILE [217]:** A deep clustering algorithm that handles unmatched feature types, removes batch effects, and learns discriminative representations through a cell-pairing maximization algorithm.</span><br><span class="line"></span><br><span class="line">- **GLUER [219]:** Combines Non-Negative Matrix Factorization (NMF), mutual nearest neighbors, and a Deep Neural Network (DNN) to integrate multi-omics data, creating co-embedded datasets.</span><br><span class="line"></span><br><span class="line">- **scPoli [220]:** A semi-supervised conditional deep generative model for data integration, label transfer, and query-to-reference mapping, handling unknown cell populations with uncertainty mechanisms.</span><br><span class="line"></span><br><span class="line">- **BAVARIA [221]:** An AE-based method for integrating and correcting batch effects across various scATAC-seq protocols, enabling precise analysis of complex datasets.</span><br><span class="line"></span><br><span class="line">- **SciPENN [222]:** A multi-use DL approach supporting CITE-seq and scRNA-seq data integration, protein expression prediction, and label transfer across modalities.</span><br><span class="line"></span><br><span class="line">- **BABEL [86]:** Integrates chromatin profiles and transcriptomes using a DNN, enabling mutual prediction of scRNA-seq and scATAC-seq data along with protein epitope profiling.</span><br><span class="line"></span><br><span class="line">- **DeepMAPS [219]:** A transformer-based platform with graph attention mechanisms for integrating multi-omics spatial data.</span><br><span class="line"></span><br><span class="line">- **Manifold-Aligning GAN (MAGAN) [214]:** Aligns different data manifolds using GANs for integrated single-cell data analysis, effective in cross-modal integration tasks.</span><br><span class="line"></span><br><span class="line">- **ExpiMap [89]:** Employs conditional VAEs for enhanced atlas integration, capturing biologically significant gene programs with interpretability.</span><br><span class="line"></span><br><span class="line">**Challenges:**</span><br><span class="line"></span><br><span class="line">- **Heterogeneity of Data Modalities:** Different omics data types have distinct distributions and noise characteristics, complicating integration.</span><br><span class="line">  </span><br><span class="line">- **Scalability and Efficiency:** Integrating large-scale, high-dimensional datasets requires models that are both computationally efficient and scalable.</span><br><span class="line">  </span><br><span class="line">- **Preservation of Biological Signals:** Ensuring that integration methods maintain or enhance the biological relevance of the data while removing technical noise is critical.</span><br><span class="line"></span><br><span class="line">**Future Directions:**</span><br><span class="line"></span><br><span class="line">As single-cell multimodal omics technologies advance, DL models will become increasingly integral for integrating diverse data types. Future research will likely focus on developing more scalable architectures, improving the preservation of biological signals, and enhancing the interpretability of integrated models. Additionally, models that can seamlessly handle new modalities and adapt to varying data qualities will be essential for advancing comprehensive single-cell analyses.</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 单细胞多组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>RNN实战</title>
      <link href="/2024/10/22/RNN%E5%AE%9E%E6%88%98/"/>
      <url>/2024/10/22/RNN%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<p>https://www.bilibili.com/video/BV1dZ4y1g7DE # RNN</p><p>单向RNN主要是包含过去的信息</p><p>双向RNN 可以同时获取过去和未来的信息</p><p><img src="https://pic.imgdb.cn/item/66f66a65f21886ccc0f00f97.png" /></p><p>每一个<span class="math inline">\(h_{t}\)</span>都是由前一刻的<span class="math inline">\(h_{t-1}\)</span>和此刻的输入<span class="math inline">\(x_{t}\)</span>的线性变换组成</p><p>向量长度是hidden_size 维度是input_size</p><p>batch_first 默认是False 打开之后数据格式就是（batch seq feature）</p><p><img src="https://pic.imgdb.cn/item/66f673aff21886ccc0fa48bd.png" /></p><p>比如这里batchsize是1，然后序列长度是2，维度（特征数）是3</p>]]></content>
      
      
      <categories>
          
          <category> 上课笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 深度学习 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>配置CUDA</title>
      <link href="/2024/09/26/%E9%85%8D%E7%BD%AECUDA/"/>
      <url>/2024/09/26/%E9%85%8D%E7%BD%AECUDA/</url>
      
        <content type="html"><![CDATA[<h1 id="配置cuda">配置CUDA</h1><p>cuda版本 根据pytorch选择</p><p>https://pytorch.org/get-started/locally/</p><p>https://pytorch.org/get-started/previous-versions/</p><p><a href="https://blog.csdn.net/lvyuanj/article/details/139257068">torch cuda 环境检测失败</a></p><p>debug过程中遇到了一个弱智的错误，就是第一个有结果，后面两个都没有结果torch.version.cuda返回None，网上一般的说法是因为pytorch安装的是cpu版本，需要重新安装GPU版本。但是我分不清是我重新下载解决的这个bug，还是因为vscode里没有重启解决的，所以还是记录一下吧</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(torch.__version__) <span class="comment"># 查看torch版本</span></span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available()) torch</span><br><span class="line"><span class="built_in">print</span>(torch.version.cuda)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> bug解决日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> None </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Sctail论文阅读</title>
      <link href="/2024/09/12/Sctail%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
      <url>/2024/09/12/Sctail%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<p>论文链接:<a href="https://www.biorxiv.org/content/10.1101/2024.07.05.602174v1.full.pdf">scTail: precise polyadenylation site detection and its alternative usage analysis from reads 1 preserved 3’ scRNA-seq data</a> # Sctail</p><ul><li>使用read1 5‘端测序，来识别PAS</li><li>然后使用read2 3’端来量化表达量</li><li>APA<ul><li>单个基因选择的PAS位点，就是添加polyA的位点可以不同</li></ul></li><li>目前的识别PAS的方法<ul><li>实验直接测得，所谓的PAS-seq<ul><li>PolyA-seq、PAS-seq、3’READS和QuantSeq REV</li></ul></li><li>通过单细胞RNA-seq，再结合生物信息分析得到<ul><li>scAPA、Sierra、scDaPars、MAAPER、scAPAtrap、SCAPTURE、SCAPE和Infernape</li></ul></li></ul></li></ul><h1 id="introduction">Introduction</h1><ul><li>（A） flow chart of the 3’ scRNA-seq gene expression library construction (10x Genomics).、</li><li>（B）直方图显示了每个转录本的reads 1 5‘端和reads 2 3’端的末端到注释的PAS的最常见距离。</li></ul><p><img src="https://pic.imgdb.cn/item/66e23ca4d9c307b7e912ffa8.png" /></p><ul><li>这里有点看不懂<ul><li>IGV的截图显示了正向链基因S100A9的reads 1、reads 2和总reads的覆盖情况。</li><li>直方图显示了正向链基因S100A9的reads 1或reads 2与注释PAS之间的距离。</li><li>IGV的截图显示了反向链基因DUSP1的reads 1、reads 2和总reads的覆盖情况。</li><li>IGV的截图显示了反向链基因DUSP1的reads 1、reads 2和总reads的覆盖情况。</li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/66e242bed9c307b7e91f8df4.png" /></p><p>在单细胞3' RNA测序中，大多数方法和平台主要关注reads 2，而忽视了reads 1中的数据。reads 1中的cDNA能够捕获接近poly(dT)序列的区域，并可用于精确地检测PAS。</p>]]></content>
      
      
      <categories>
          
          <category> 论文阅读 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> PAS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>蛋白质组学</title>
      <link href="/2024/09/11/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%84%E5%AD%A6/"/>
      <url>/2024/09/11/%E8%9B%8B%E7%99%BD%E8%B4%A8%E7%BB%84%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<h1>蛋白质组学</h1><p>“multi_match_nonutr”, “multi_match_utr”</p><p>“multi_unmatch_nonutr”, “multi_unmatch_utr”</p>]]></content>
      
      
      <categories>
          
          <category> 上课笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> None </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>bedtools使用记录</title>
      <link href="/2024/09/09/bedtools/"/>
      <url>/2024/09/09/bedtools/</url>
      
        <content type="html"><![CDATA[<h1 id="bedtools">bedtools</h1><h2 id="bed-format">BED format</h2><p><img src="https://pic.imgdb.cn/item/66de5dd1d9c307b7e950d2b5.png" /></p><ul><li>BED的全称是“Browser Extensible Data”，用于存储基因组区域</li><li>BED文件包含基因组区域的信息。<ul><li><strong>0-based坐标系</strong>：使用0作为基因组坐标的起始点。</li></ul></li><li><strong>Tab (</strong>分隔的，每一行代表一个基因组区域</li><li>命令行工具<ul><li>BEDtools 命令行工具</li><li><a href="https://bedtools.readthedocs.io/en/latest/">文档链接</a></li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/66de5fb6d9c307b7e952cb07.png" /></p><ul><li>BED文件必须包含<ul><li><code>chrom</code>（染色体）: 表示基因或者基因组段所在的染色体。</li><li><code>start</code>（起始点）: 表示基因组段起始位置的坐标。</li><li><code>end</code>（终止点）: 表示基因组段终止位置的坐标。</li></ul></li><li>两种数据格式<ul><li>UCSC BED：专门为使用UCSC基因组浏览器设计的格式</li><li>Everything else：不同的软件或数据库。</li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/66de714dd9c307b7e96ce7e1.png" /></p><p>可以为每个基因的位置添加分数，然后来进行生物信息的操作</p><h2 id="base-vs-1-base">0-base vs 1-base</h2><p><img src="https://pic.imgdb.cn/item/66de72c6d9c307b7e96ec4e8.png" /></p><ul><li>不同类型的坐标系</li></ul><p><img src="https://pic.imgdb.cn/item/66de73d1d9c307b7e96ffece.png" /></p><ul><li>一个不太精确的经验规则，即如果文件的内容是以文本形式直观易读的，那么它可能使用的是1-based坐标系统。这种经验规则并不是绝对的，但是在处理文本格式的生物信息文件时，这可以作为一个初步的判断依据。</li></ul><h2 id="convert-vcf-to-bed-with-awk">Convert VCF to BED with awk</h2><p>将VCF文件转换为BED文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grep -v <span class="string">&quot;#&quot;</span> 1000G_omni2.5.b37.sites.vcf | awk <span class="string">&#x27;&#123; print $1&quot;\t&quot;$2-1&quot;\t&quot;$2&quot;\t&quot;$3 &#125;&#x27;</span> &gt; 1kgp_omni2.5.hg19.bed</span><br><span class="line"></span><br></pre></td></tr></table></figure><blockquote><p><strong>grep命令</strong>：使用<code>grep -v "#" 1000G_omni2.5.b37.sites.vcf</code>这个命令从VCF文件中过滤出所有非注释行（即不含“#”的行）。这些行通常包含关于变异位点（如单核苷酸多态性，SNPs）的具体数据。</p><p><strong>awk命令</strong>：通过管道<code>|</code>将grep的输出传递给awk命令处理。awk命令用于处理文本数据和生成格式化报告。这里的命令<code>awk '&#123; print $1"\t"$2-1"\t"$2"\t"$3 &#125;'</code>执行以下操作：</p><ul><li><code>$1</code>：打印第一个字段，通常是染色体名。</li><li><code>$2-1</code>和<code>$2</code>（<strong>重点</strong>）：因为VCF文件是1-based（即坐标从1开始），而BED文件是0-based（坐标从0开始），所以将起始位置减1，将结束位置设为原始起始位置，以转换坐标系统。</li><li><code>$3</code>：通常为变异位点的ID。</li></ul><p><strong>输出重定向</strong>：最后的输出通过重定向<code>&gt;</code>保存到一个新的BED文件<code>1kgp_omni2.5.hg19.bed</code>中。</p></blockquote><ul><li>为什么使用BEDtools<ul><li>在基因组学分析中，经常需要研究特定的基因组区域对疾病或表型的影响。<strong>使用BEDTools可以方便地将变异数据（VCF格式）与感兴趣的区域</strong>（如特定基因、已知敏感或黑名单区域）进行相交分析，从而识别重要的基因组变异。</li></ul></li></ul><h2 id="sorted-bed-files">sorted BED files</h2><p>unix sort command</p><ul><li>命名文件 分享的时候，在文件名后面最好打上参考基因组</li></ul><p>这张图片显示了一系列在命令行中使用的命令，它们涉及到对BED文件的排序、压缩、检查大小和索引。这些命令是：</p><ol type="1"><li><p><strong>排序 BED 文件</strong>: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sort</span> -k1,1 -k2,2n 1kgp_omni2.5.hg19.bed &gt; tmp; <span class="built_in">mv</span> tmp 1kgp_omni2.5.hg19.bed</span><br></pre></td></tr></table></figure> 这条命令将<code>1kgp_omni2.5.hg19.bed</code>文件按照染色体名（第一列）和起始位置（第二列）进行排序。结果首先写入临时文件<code>tmp</code>，然后用<code>mv</code>命令将<code>tmp</code>文件替换原文件。</p></li><li><p><strong>压缩 BED 文件</strong>: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bgzip -f 1kgp_omni2.5.hg19.bed</span><br></pre></td></tr></table></figure> 使用<code>bgzip</code>命令压缩排序后的BED文件。<code>-f</code>选项强制压缩，即使目标文件已经存在也会被覆盖。</p></li><li><p><strong>查看压缩文件的大小</strong>: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">du</span> -sch 1kgp_omni2.5.hg19.bed.gz</span><br></pre></td></tr></table></figure> <code>du</code>命令用来检查文件大小。<code>-sch</code>选项表示：</p><ul><li><code>-s</code>：仅显示总计。</li><li><code>-c</code>：除了列出各个文件的大小，还要显示所有文件的总和。</li><li><code>-h</code>：以易读格式（如K, M）显示大小。 这个命令显示压缩后的文件大小为26M。</li></ul></li><li><p><strong>索引压缩文件</strong>: <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tabix -p bed 1kgp_omni2.5.hg19.bed.gz</span><br></pre></td></tr></table></figure> <code>tabix</code>是用于索引基于文本的数据文件的工具，使得可以快速检索文件中的某个区域。<code>-p bed</code>指定了文件格式为BED，这是必要的参数，以便<code>tabix</code>知道如何解析文件。</p></li></ol>]]></content>
      
      
      <categories>
          
          <category> 生物信息工具使用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> bedtools </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>表观基因组学</title>
      <link href="/2024/07/20/%E8%A1%A8%E8%A7%82%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/"/>
      <url>/2024/07/20/%E8%A1%A8%E8%A7%82%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<ul><li>表观基因组学和环境有关</li></ul><blockquote><p>定义：在核苷酸序列不发生改变的情况下，研究基因组上的化学修饰和空间结构变化如何影响基因功能和表达调控的一门学科。</p></blockquote><ul><li>研究内容：<ul><li>化学修饰：DNA、RNA、 蛋白质</li><li>空间结构：核小体 （nucleosome）、染色质（chromatin）、基因组</li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/669c9aaed9c307b7e95d7333.png" alt=""></p><p>每个阶段都有很多的化学修饰，而且是可逆的</p><h1>DNA修饰</h1><p>甲基化 Methylation 最重要的修饰 给碱基带个帽子</p><p><img src="https://pic.imgdb.cn/item/669e14f4d9c307b7e9b852d3.png" alt=""></p><ul><li>几种类型，一般是指5mC的</li></ul><p><img src="https://pic.imgdb.cn/item/669e24f2d9c307b7e9c86891.png" alt=""></p><p>5甲基胞嘧啶事表观遗传中最重要的一种修饰</p><ul><li><p>人类5mC甲基化特点</p><ul><li>人类基因组中大约含有3千万个CpG二核苷酸</li><li>除了胚胎和脑组织，其它组织的5mC甲基化通常发生在CpG二核苷酸上</li><li>CpG岛甲基化水平较低，非CpG岛甲基化水平较高<br>人类一生中5mC的含量动态变化</li><li>受精过程中会发生5mC重编程</li></ul></li><li><p>甲基化可以抑制转录可移动元件（transposable elements，简称TEs）的活动</p><ul><li>TEs的活动可以引起DNA重排、插入突变等，威胁基因组的稳定性。通过甲基化抑制这些元件的表达，可以防止它们跳跃到基因组的其他部位，从而维持基因组的完整性和稳定性。</li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/669f7746d9c307b7e9e2aa9c.png" alt=""></p><h2 id="DNA的甲基化功能">DNA的甲基化功能</h2><p><img src="https://pic.imgdb.cn/item/669f799ed9c307b7e9e4bac9.png" alt=""></p><p>基因印记：基因本身序列不变的情况下，通过DNA的甲基化或者组蛋白的甲基化影响力基因的表达的现象</p><h1>RNA修饰</h1><p><img src="https://pic.imgdb.cn/item/66a36de2d9c307b7e97bc9b6.png" alt=""></p><ul><li>RNA编辑</li></ul><h1>蛋白质修饰</h1><h2 id="翻译后修饰">翻译后修饰</h2><p><img src="https://pic.imgdb.cn/item/66a5f7d0d9c307b7e990c01e.png" alt=""></p><blockquote><p><strong>磷酸化</strong>：通过添加磷酸基团到丝氨酸、苏氨酸或酪氨酸残基，影响蛋白质的活性和功能。</p><p><strong>泛素化</strong>：通过添加泛素蛋白来标记蛋白质，通常与蛋白质的降解过程相关。</p><p><strong>甲基化</strong>：添加甲基团到氨基酸的侧链，可以改变蛋白质的相互作用和功能。</p><p><strong>乙酰化</strong>：在蛋白质的赖氨酸残基上添加乙酰基，通常影响蛋白质如何与DNA结合及其转录活性。</p><p><strong>糖基化</strong>：添加糖链到特定的氨基酸残基上，这种修饰在细胞信号传递和蛋白质折叠中起着重要角色。</p></blockquote><h2 id="组蛋白修饰">组蛋白修饰</h2><p><img src="https://pic.imgdb.cn/item/66a60228d9c307b7e99b684a.png" alt=""></p><ul><li>组蛋白修饰命名规则</li></ul><p><img src="https://pic.imgdb.cn/item/66a60ec6d9c307b7e9a9e8ab.png" alt=""></p><p><img src="https://pic.imgdb.cn/item/66a610b4d9c307b7e9ab8df5.png" alt=""></p><p>不同年龄的DNA和组蛋白甲基化差异</p><h1>三维基因组学</h1><p><img src="https://pic.imgdb.cn/item/66a61304d9c307b7e9ad5524.png" alt=""></p><p>比如这里A和C在空间上的距离比较近，就容易发生相互作用</p>]]></content>
      
      
      <categories>
          
          <category> 生物信息 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 表观基因组学 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>转录组学</title>
      <link href="/2024/07/20/%E8%BD%AC%E5%BD%95%E7%BB%84%E5%AD%A6/"/>
      <url>/2024/07/20/%E8%BD%AC%E5%BD%95%E7%BB%84%E5%AD%A6/</url>
      
        <content type="html"><![CDATA[<ul><li>可以看出哪些基因是正调控，哪些是负调控</li></ul><p><img src="https://pic.imgdb.cn/item/669b689dd9c307b7e932b885.png" /></p><ul><li>计算相关系数，不同的点是不同的实验条件<ul><li>右下角聚类可以发现哪些基因之间相互有关，可能共同调控</li></ul></li></ul><p><img src="https://pic.imgdb.cn/item/669b69fed9c307b7e934be68.png" /></p><p><img src="https://pic.imgdb.cn/item/669b6bdad9c307b7e93773b9.png" /></p><ul><li>管家基因和组织特异基因<ul><li>house keeping genes 和tissue specific genes</li><li>管家基因基本都会打开，组织特异性基因就会在不同组织间打开或关闭有区别</li></ul></li><li>做一些GO terms的分析<ul><li><img src="https://pic.imgdb.cn/item/669b6d6ed9c307b7e939915a.png" /></li></ul></li><li>单细胞转录组学<ul><li><img src="https://pic.imgdb.cn/item/669b6e89d9c307b7e93c7f34.png" /></li></ul></li><li>空间转录组学<ul><li>除了细胞类型还要加上位置</li><li><img src="https://pic.imgdb.cn/item/669b6eaed9c307b7e93cb318.png" /></li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> 生物信息 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 转录组学 </tag>
            
            <tag> RNA-seq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Butterfly主题界面</title>
      <link href="/2024/07/19/Butterfly%E4%B8%BB%E9%A2%98%E9%A1%B5%E9%9D%A2/"/>
      <url>/2024/07/19/Butterfly%E4%B8%BB%E9%A2%98%E9%A1%B5%E9%9D%A2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>https://www.bilibili.com/video/BV1Ko4y1S7mv/?p=11 hexo clean hexo g hexo d</p></blockquote><h1 id="主题界面">主题界面</h1><p><a href="https://butterfly.js.org/posts/dc584b87/">Butterfly主题页面</a></p><ul><li>标签页</li></ul><blockquote><p>hexo new page tags</p></blockquote><ul><li>分类页</li></ul><blockquote><p>hexo new page categories</p></blockquote><ul><li>友情链接<ul><li>创建并修改yml文件内容，添加想要关联到的链接</li><li>**source/_data link.yml**</li></ul></li></ul><blockquote><p>hexo new page link</p></blockquote><ul><li>404页面<ul><li>根目录-&gt;node_modules-&gt;hexo-theme-butterfly-YML &gt;_config.yml</li><li>先找到这个文件，复制内容，在根目录下创建 _config.butterfly.yml，粘贴进去内容。</li><li>在其中找到404那块，把false改成true</li></ul></li></ul><h1 id="主题配置1">主题配置1</h1><ul><li>导航菜单<ul><li>menu<ul><li><img src="https://pic.imgdb.cn/item/669a30d6d9c307b7e9e0850f.png" /></li></ul></li><li>路径是自动匹配source文件夹里的路径的</li><li>配置成功就会出现导航栏</li></ul></li><li>代码块<ul><li>4.1. 代碼高亮主題 4.2. 代碼複製 4.3. 代碼框展開/關閉 4.4. 代碼換行 4.5. 代碼高度限制</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">highlight_theme: mac light #  darker / pale night / light / ocean / mac / mac light / false</span><br><span class="line">highlight_copy: true # copy button</span><br><span class="line">highlight_lang: true # show the code language</span><br><span class="line">highlight_shrink: false # true: shrink the code blocks / false: expand the code blocks | none: expand code blocks and hide the button</span><br><span class="line">highlight_height_limit: false # unit: px</span><br><span class="line">code_word_wrap: false</span><br></pre></td></tr></table></figure><ul><li><p>社交图标</p><ul><li><p>Butterfly支持 <a href="https://fontawesome.com/icons?from=io">font-awesome v6</a> 圖標.</p></li><li><p>在这个网站上我们可以搜索到想要的图标，然后获得图标名字，放在代码的这个位置上就行了，后面加上链接<img src="https://pic.imgdb.cn/item/669a3508d9c307b7e9e38ee7.png" /></p></li></ul></li><li><p>主页文章自动节选</p></li><li><p>顶部图</p><ul><li>首页 分类页上面最大的那个图 可以分别单独设置</li><li>disable_top_img先改成false</li><li>图片的加载除了<strong>在线链接</strong>之外，还可以是<strong>本地添加</strong></li><li><img src="https://pic.imgdb.cn/item/669a3b4bd9c307b7e9ea9f3d.png" /></li><li>更多图片类型等待设置<ul><li><img src="https://pic.imgdb.cn/item/669a41fcd9c307b7e9f09b2d.png" /></li></ul></li><li>tag页和cate页的图片是需要单独去md文件里配置的<ul><li><img src="https://pic.imgdb.cn/item/669a42cbd9c307b7e9f133dd.png" /></li></ul></li></ul></li><li><p>置顶文章</p><ul><li><img src="https://pic.imgdb.cn/item/669a46ddd9c307b7e9f54d5b.png" /></li></ul></li><li><p>文章封面</p><ul><li><p>butterfly里统一设置</p><ul><li>cover:<ul><li>后面进行一系列配置</li></ul></li><li>default_cover<ul><li>可以设置多张默认封面，如果文章没有单独设置封面则会进行随机选择</li></ul></li></ul></li><li><blockquote><p>文章封面的獲取順序 Front-matter 的 cover &gt; 配置文件的 default_cover &gt; false</p></blockquote></li><li><p>每个文章在开头单独设置cover</p></li></ul></li><li><p>版权</p><ul><li>统一设置<ul><li>主题配置文章里打开Copyright</li></ul></li><li>文章单独设置<ul><li>每个文章开头可以单独设置，比如这篇是转载的，就可以把copyright关起来</li></ul></li></ul></li><li><p>目录</p><ul><li>toc</li><li><img src="https://pic.imgdb.cn/item/669b3e59d9c307b7e9f9e2a7.png" /></li><li>同样也是可以单独设置文章<ul><li>在你的文章md文件的頭部，加入toc_number和toc，並配置true或者false即可。</li></ul></li></ul></li><li><p>相关文章推荐</p><ul><li>related_post</li><li>根据tag推荐</li></ul></li><li><p>头像</p><ul><li>avatar</li></ul></li><li><p>阅读模式 夜间模式</p></li><li><p>图片文字描述</p></li><li><p>footer 页脚定义文件</p></li></ul><p>之后更多的请参考官方文档，懒得记了</p><h1 id="待定的">待定的</h1><ul><li>部署到服务器上</li><li>待解决问题<ul><li>无法显示latex公式</li></ul></li></ul>]]></content>
      
      
      <categories>
          
          <category> Hexo教程 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 页面配置 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第二篇博客</title>
      <link href="/2024/07/19/%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
      <url>/2024/07/19/%E7%AC%AC%E4%BA%8C%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h2 id="quick-start">Quick Start</h2><p>1234</p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> None </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>第一篇博客</title>
      <link href="/2024/07/19/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/"/>
      <url>/2024/07/19/%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2/</url>
      
        <content type="html"><![CDATA[<h1 id="第一章">第一章</h1><p>第一篇博客记录一下hexo搭建过程中的bug</p><ul><li>原本在hexo d之后的报错</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">(base) xuan@wangzixuandeMacBook-Pro BlogFile % hexo d</span><br><span class="line">（省略。。）</span><br><span class="line">Username for &#x27;https://github.com&#x27;: wanziw</span><br><span class="line">Password for &#x27;https://wanziw@github.com&#x27;: </span><br><span class="line">remote: Support for password authentication was removed on August 13, 2021.</span><br><span class="line">remote: Please see https://docs.github.com/get-started/getting-started-with-git/about-remote-repositories#cloning-with-https-urls for information on currently recommended modes of authentication.</span><br><span class="line">fatal: Authentication failed for &#x27;https://github.com/wanziw/wanziw.github.io.git/&#x27;</span><br><span class="line">FATAL Something&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span><br></pre></td></tr></table></figure><p>根据问题发现是要创建令牌（token），在输入密码的部分要输入token</p><p><a href="https://blog.csdn.net/weixin_45844049/article/details/123733065">Git The requested URL returned error: 403，Token authentication requirements for Git operations</a></p><ul><li>结果创建完之后报错如下</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">fatal: unable to access &#x27;https://github.com/wanziw/wanziw.github.io.git/&#x27;: The requested URL returned error: 403</span><br><span class="line">FATAL Something&#x27;s wrong. Maybe you can find the solution here: https://hexo.io/docs/troubleshooting.html</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>解决方案：</p><p>发现创建错了，我创建成上面那个Fine-grained的了，其实应该创建下面那个</p><p><img src="https://pic.imgdb.cn/item/669a0b5ad9c307b7e9bb84bc.png" /></p><p>这玩意过期expired也会报这个bug 参考链接：https://www.jianshu.com/p/d5f2e04a332f</p>]]></content>
      
      
      <categories>
          
          <category> bug解决日记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> None </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2024/07/19/hello-world/"/>
      <url>/2024/07/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> test </category>
          
      </categories>
      
      
        <tags>
            
            <tag> None </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
